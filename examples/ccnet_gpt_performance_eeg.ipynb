{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "        Kim, Jinsu \n",
    "\n",
    "        KIM, JeongYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_append = \"../\"\n",
    "sys.path.append(path_append)  # Go up one directory from where you are.\n",
    "\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>D24</th>\n",
       "      <th>D25</th>\n",
       "      <th>D26</th>\n",
       "      <th>D27</th>\n",
       "      <th>D28</th>\n",
       "      <th>D29</th>\n",
       "      <th>D30</th>\n",
       "      <th>D31</th>\n",
       "      <th>D32</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3549.790315</td>\n",
       "      <td>4533.538497</td>\n",
       "      <td>3619.665186</td>\n",
       "      <td>3077.291188</td>\n",
       "      <td>-1380.325575</td>\n",
       "      <td>6120.066816</td>\n",
       "      <td>-4072.820600</td>\n",
       "      <td>-2256.511456</td>\n",
       "      <td>1820.012261</td>\n",
       "      <td>-2815.635423</td>\n",
       "      <td>...</td>\n",
       "      <td>-7240.845997</td>\n",
       "      <td>7034.252627</td>\n",
       "      <td>8458.062496</td>\n",
       "      <td>5905.223463</td>\n",
       "      <td>6147.660515</td>\n",
       "      <td>2458.073582</td>\n",
       "      <td>-7465.876831</td>\n",
       "      <td>-3604.133966</td>\n",
       "      <td>-5445.224315</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3551.227812</td>\n",
       "      <td>4534.850995</td>\n",
       "      <td>3622.540181</td>\n",
       "      <td>3077.322438</td>\n",
       "      <td>-1377.575581</td>\n",
       "      <td>6123.066810</td>\n",
       "      <td>-4069.851856</td>\n",
       "      <td>-2252.167714</td>\n",
       "      <td>1825.168502</td>\n",
       "      <td>-2803.072947</td>\n",
       "      <td>...</td>\n",
       "      <td>-7227.283522</td>\n",
       "      <td>7039.627617</td>\n",
       "      <td>8463.874985</td>\n",
       "      <td>5911.598451</td>\n",
       "      <td>6153.504254</td>\n",
       "      <td>2463.354822</td>\n",
       "      <td>-7461.033090</td>\n",
       "      <td>-3594.258985</td>\n",
       "      <td>-5435.693082</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3556.727802</td>\n",
       "      <td>4539.850986</td>\n",
       "      <td>3629.040169</td>\n",
       "      <td>3081.978679</td>\n",
       "      <td>-1370.419344</td>\n",
       "      <td>6130.348047</td>\n",
       "      <td>-4063.508118</td>\n",
       "      <td>-2249.292720</td>\n",
       "      <td>1828.074746</td>\n",
       "      <td>-2804.041695</td>\n",
       "      <td>...</td>\n",
       "      <td>-7227.158522</td>\n",
       "      <td>7048.502600</td>\n",
       "      <td>8473.562467</td>\n",
       "      <td>5921.348433</td>\n",
       "      <td>6163.004236</td>\n",
       "      <td>2469.854810</td>\n",
       "      <td>-7460.470591</td>\n",
       "      <td>-3591.540240</td>\n",
       "      <td>-5433.568086</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3557.915300</td>\n",
       "      <td>4541.225983</td>\n",
       "      <td>3628.540169</td>\n",
       "      <td>3083.197427</td>\n",
       "      <td>-1372.263090</td>\n",
       "      <td>6130.410547</td>\n",
       "      <td>-4062.070620</td>\n",
       "      <td>-2251.667715</td>\n",
       "      <td>1825.856000</td>\n",
       "      <td>-2803.572946</td>\n",
       "      <td>...</td>\n",
       "      <td>-7224.189777</td>\n",
       "      <td>7042.346362</td>\n",
       "      <td>8464.593734</td>\n",
       "      <td>5917.660940</td>\n",
       "      <td>6160.972990</td>\n",
       "      <td>2467.011066</td>\n",
       "      <td>-7458.158095</td>\n",
       "      <td>-3597.008980</td>\n",
       "      <td>-5437.474329</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3553.352808</td>\n",
       "      <td>4535.757243</td>\n",
       "      <td>3622.477681</td>\n",
       "      <td>3079.572434</td>\n",
       "      <td>-1377.763080</td>\n",
       "      <td>6125.598056</td>\n",
       "      <td>-4066.570612</td>\n",
       "      <td>-2255.136459</td>\n",
       "      <td>1821.981008</td>\n",
       "      <td>-2808.041687</td>\n",
       "      <td>...</td>\n",
       "      <td>-7219.971035</td>\n",
       "      <td>7044.658857</td>\n",
       "      <td>8466.843729</td>\n",
       "      <td>5914.848445</td>\n",
       "      <td>6156.785498</td>\n",
       "      <td>2466.948566</td>\n",
       "      <td>-7457.501846</td>\n",
       "      <td>-3585.821500</td>\n",
       "      <td>-5428.630595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588018</th>\n",
       "      <td>-623.326974</td>\n",
       "      <td>2269.261431</td>\n",
       "      <td>2575.479615</td>\n",
       "      <td>285.733846</td>\n",
       "      <td>907.388947</td>\n",
       "      <td>-491.014719</td>\n",
       "      <td>-2998.447586</td>\n",
       "      <td>1886.043389</td>\n",
       "      <td>1659.637557</td>\n",
       "      <td>416.296105</td>\n",
       "      <td>...</td>\n",
       "      <td>-7176.689865</td>\n",
       "      <td>2116.667963</td>\n",
       "      <td>-901.138961</td>\n",
       "      <td>-227.327706</td>\n",
       "      <td>-657.170662</td>\n",
       "      <td>3025.322534</td>\n",
       "      <td>-12313.149124</td>\n",
       "      <td>-3810.071086</td>\n",
       "      <td>-5620.505241</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588019</th>\n",
       "      <td>-627.420717</td>\n",
       "      <td>2264.448940</td>\n",
       "      <td>2570.323375</td>\n",
       "      <td>281.077605</td>\n",
       "      <td>903.482705</td>\n",
       "      <td>-490.702219</td>\n",
       "      <td>-3001.260080</td>\n",
       "      <td>1884.387142</td>\n",
       "      <td>1657.012562</td>\n",
       "      <td>414.702358</td>\n",
       "      <td>...</td>\n",
       "      <td>-7179.502360</td>\n",
       "      <td>2118.074210</td>\n",
       "      <td>-900.607712</td>\n",
       "      <td>-227.046456</td>\n",
       "      <td>-659.389408</td>\n",
       "      <td>3027.760030</td>\n",
       "      <td>-12307.211635</td>\n",
       "      <td>-3809.946086</td>\n",
       "      <td>-5621.098990</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588020</th>\n",
       "      <td>-631.764459</td>\n",
       "      <td>2260.730197</td>\n",
       "      <td>2566.917131</td>\n",
       "      <td>275.546365</td>\n",
       "      <td>902.045207</td>\n",
       "      <td>-493.545964</td>\n",
       "      <td>-3006.103821</td>\n",
       "      <td>1886.199639</td>\n",
       "      <td>1658.512560</td>\n",
       "      <td>424.202340</td>\n",
       "      <td>...</td>\n",
       "      <td>-7177.439864</td>\n",
       "      <td>2118.199210</td>\n",
       "      <td>-900.920211</td>\n",
       "      <td>-226.140208</td>\n",
       "      <td>-659.764407</td>\n",
       "      <td>3027.103781</td>\n",
       "      <td>-12305.774138</td>\n",
       "      <td>-3805.633594</td>\n",
       "      <td>-5614.880251</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588021</th>\n",
       "      <td>-625.076971</td>\n",
       "      <td>2265.605188</td>\n",
       "      <td>2573.354619</td>\n",
       "      <td>281.702604</td>\n",
       "      <td>904.982702</td>\n",
       "      <td>-490.795969</td>\n",
       "      <td>-3001.416330</td>\n",
       "      <td>1888.387135</td>\n",
       "      <td>1659.418808</td>\n",
       "      <td>420.077348</td>\n",
       "      <td>...</td>\n",
       "      <td>-7172.002374</td>\n",
       "      <td>2119.730457</td>\n",
       "      <td>-898.170216</td>\n",
       "      <td>-224.515211</td>\n",
       "      <td>-656.576913</td>\n",
       "      <td>3032.822520</td>\n",
       "      <td>-12303.742892</td>\n",
       "      <td>-3804.133597</td>\n",
       "      <td>-5614.192752</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588022</th>\n",
       "      <td>-623.639474</td>\n",
       "      <td>2268.636432</td>\n",
       "      <td>2576.229614</td>\n",
       "      <td>286.515095</td>\n",
       "      <td>909.795193</td>\n",
       "      <td>-484.358481</td>\n",
       "      <td>-2996.353839</td>\n",
       "      <td>1895.730871</td>\n",
       "      <td>1668.950040</td>\n",
       "      <td>431.983576</td>\n",
       "      <td>...</td>\n",
       "      <td>-7171.908624</td>\n",
       "      <td>2129.230440</td>\n",
       "      <td>-889.357733</td>\n",
       "      <td>-216.577726</td>\n",
       "      <td>-649.358176</td>\n",
       "      <td>3039.572508</td>\n",
       "      <td>-12297.899153</td>\n",
       "      <td>-3793.383617</td>\n",
       "      <td>-5603.130273</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588023 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A1           A2           A3           A4           A5  \\\n",
       "0       3549.790315  4533.538497  3619.665186  3077.291188 -1380.325575   \n",
       "1       3551.227812  4534.850995  3622.540181  3077.322438 -1377.575581   \n",
       "2       3556.727802  4539.850986  3629.040169  3081.978679 -1370.419344   \n",
       "3       3557.915300  4541.225983  3628.540169  3083.197427 -1372.263090   \n",
       "4       3553.352808  4535.757243  3622.477681  3079.572434 -1377.763080   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "588018  -623.326974  2269.261431  2575.479615   285.733846   907.388947   \n",
       "588019  -627.420717  2264.448940  2570.323375   281.077605   903.482705   \n",
       "588020  -631.764459  2260.730197  2566.917131   275.546365   902.045207   \n",
       "588021  -625.076971  2265.605188  2573.354619   281.702604   904.982702   \n",
       "588022  -623.639474  2268.636432  2576.229614   286.515095   909.795193   \n",
       "\n",
       "                 A6           A7           A8           A9          A10  ...  \\\n",
       "0       6120.066816 -4072.820600 -2256.511456  1820.012261 -2815.635423  ...   \n",
       "1       6123.066810 -4069.851856 -2252.167714  1825.168502 -2803.072947  ...   \n",
       "2       6130.348047 -4063.508118 -2249.292720  1828.074746 -2804.041695  ...   \n",
       "3       6130.410547 -4062.070620 -2251.667715  1825.856000 -2803.572946  ...   \n",
       "4       6125.598056 -4066.570612 -2255.136459  1821.981008 -2808.041687  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "588018  -491.014719 -2998.447586  1886.043389  1659.637557   416.296105  ...   \n",
       "588019  -490.702219 -3001.260080  1884.387142  1657.012562   414.702358  ...   \n",
       "588020  -493.545964 -3006.103821  1886.199639  1658.512560   424.202340  ...   \n",
       "588021  -490.795969 -3001.416330  1888.387135  1659.418808   420.077348  ...   \n",
       "588022  -484.358481 -2996.353839  1895.730871  1668.950040   431.983576  ...   \n",
       "\n",
       "                D24          D25          D26          D27          D28  \\\n",
       "0      -7240.845997  7034.252627  8458.062496  5905.223463  6147.660515   \n",
       "1      -7227.283522  7039.627617  8463.874985  5911.598451  6153.504254   \n",
       "2      -7227.158522  7048.502600  8473.562467  5921.348433  6163.004236   \n",
       "3      -7224.189777  7042.346362  8464.593734  5917.660940  6160.972990   \n",
       "4      -7219.971035  7044.658857  8466.843729  5914.848445  6156.785498   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "588018 -7176.689865  2116.667963  -901.138961  -227.327706  -657.170662   \n",
       "588019 -7179.502360  2118.074210  -900.607712  -227.046456  -659.389408   \n",
       "588020 -7177.439864  2118.199210  -900.920211  -226.140208  -659.764407   \n",
       "588021 -7172.002374  2119.730457  -898.170216  -224.515211  -656.576913   \n",
       "588022 -7171.908624  2129.230440  -889.357733  -216.577726  -649.358176   \n",
       "\n",
       "                D29           D30          D31          D32  event  \n",
       "0       2458.073582  -7465.876831 -3604.133966 -5445.224315      5  \n",
       "1       2463.354822  -7461.033090 -3594.258985 -5435.693082      5  \n",
       "2       2469.854810  -7460.470591 -3591.540240 -5433.568086      5  \n",
       "3       2467.011066  -7458.158095 -3597.008980 -5437.474329      5  \n",
       "4       2466.948566  -7457.501846 -3585.821500 -5428.630595      5  \n",
       "...             ...           ...          ...          ...    ...  \n",
       "588018  3025.322534 -12313.149124 -3810.071086 -5620.505241     10  \n",
       "588019  3027.760030 -12307.211635 -3809.946086 -5621.098990     10  \n",
       "588020  3027.103781 -12305.774138 -3805.633594 -5614.880251     10  \n",
       "588021  3032.822520 -12303.742892 -3804.133597 -5614.192752     10  \n",
       "588022  3039.572508 -12297.899153 -3793.383617 -5603.130273     10  \n",
       "\n",
       "[588023 rows x 129 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# https://github.com/N-Nieto/Inner_Speech_Dataset\n",
    "\n",
    "# Load the Inner Speech Dataset\n",
    "# =============================\n",
    "# This dataset comprises raw EEG data collected from subject 'sub-01' during session 'ses-01'.\n",
    "# Source: https://github.com/N-Nieto/Inner_Speech_Dataset\n",
    "#\n",
    "# Overview:\n",
    "# - The dataset is part of a study on inner speech, capturing brain activity via EEG.\n",
    "# - Each row in the dataset corresponds to a timestamp of EEG readings.\n",
    "# - Columns represent various EEG channels (electrodes placed on the scalp).\n",
    "#\n",
    "# Usage:\n",
    "# - The data is primarily used for cognitive neuroscience research, focusing on the neural correlates of inner speech.\n",
    "# - Users can analyze EEG signals to investigate brain activity patterns associated with the cognitive processes of inner speech.\n",
    "#\n",
    "# File Structure:\n",
    "# - Located at '../data/RAW_EEG/sub-01/sub-01_ses-01.csv' relative to this script.\n",
    "# - It is advisable to preprocess the data (filtering, normalization) before detailed analysis.\n",
    "#\n",
    "# Example:\n",
    "# - To load this data into a DataFrame for analysis and processing, use the following code snippet.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = None\n",
    "for csv in [\"../data/RAW_EEG/sub-01/sub-01_ses-01.csv\", \"../data/RAW_EEG/sub-01/sub-01_ses-02.csv\", \"../data/RAW_EEG/sub-01/sub-01_ses-03.csv\"]:\n",
    "    tmp_df = pd.read_csv(path_append + csv)\n",
    "    if df is None:\n",
    "        df = tmp_df\n",
    "    else:\n",
    "        df = pd.concat([df, tmp_df])\n",
    "df = df.reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of each class in the 'event' column:\n",
      "1     57650\n",
      "0     57650\n",
      "3     57650\n",
      "2     57650\n",
      "13    57650\n",
      "12    57650\n",
      "11    57650\n",
      "10    57650\n",
      "6     28825\n",
      "9     28825\n",
      "8     28825\n",
      "7     28825\n",
      "5     11523\n",
      "Name: event, dtype: int64\n",
      "\n",
      "Maximum class number:\n",
      "13\n",
      "\n",
      "Expected number of classes (from num_classes variable): 14\n"
     ]
    }
   ],
   "source": [
    "# Example setup, assuming df and mm are defined as DataFrame and RobustScaler respectively\n",
    "\n",
    "# Assuming df['event'] contains the class labels\n",
    "event_counts = df['event'].value_counts()\n",
    "max_class_number = df['event'].max()\n",
    "\n",
    "# Print each number of classes\n",
    "print(\"Counts of each class in the 'event' column:\")\n",
    "print(event_counts)\n",
    "\n",
    "# Print the maximum class number\n",
    "print(\"\\nMaximum class number:\")\n",
    "print(max_class_number)\n",
    "\n",
    "num_classes = max_class_number + 1\n",
    "# Additionally, verify against the num_classes variable\n",
    "print(\"\\nExpected number of classes (from num_classes variable):\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices where the 'event' label changes: [0, 3841, 4994, 6147, 8453, 9606, 10759, 11912, 13065, 14218, 15371, 17677, 18830, 19983, 21136, 23442, 24595, 25748, 26901, 28054, 29207, 30360, 31513, 33819, 34972, 36125, 38431, 39584, 40737, 41890, 45349, 46502, 48808, 49961, 52267, 55726, 56879, 58032, 60338, 61491, 62644, 63797, 66103, 67256, 68409, 69562, 70715, 71868, 73021, 74174, 75327, 77633, 78786, 81092, 82245, 83398, 85704, 86857, 88010, 89163, 90316, 91469, 92622, 94928, 96081, 98387, 101846, 102999, 104152, 106458, 107611, 108764, 109917, 112223, 113376, 114529, 115682, 116835, 117988, 119141, 120294, 121447, 123753, 124906, 127212, 128365, 129518, 131824, 132977, 134130, 135283, 136436, 137589, 138742, 141048, 142201, 143354, 144507, 146813, 149119, 150272, 151425, 152578, 153731, 157190, 158343, 160649, 161802, 162955, 164108, 165261, 166414, 168720, 169873, 172179, 173332, 175638, 176791, 179097, 180250, 181403, 182556, 183709, 184862, 186015, 187168, 188321, 190627, 192933, 194086, 195239, 196392, 197545, 198698, 199851, 202157, 203310, 204463, 205616, 207922, 209075, 210228, 211381, 214840, 215993, 217146, 218299, 219452, 220605, 221758, 222911, 224064, 225217, 226370, 228676, 229829, 230982, 232135, 233288, 234441, 238282, 239435, 240588, 241741, 245200, 246353, 248659, 250965, 252118, 253271, 254424, 255577, 256730, 257883, 259036, 260189, 261342, 264801, 265954, 268260, 269413, 270566, 271719, 274025, 275178, 276331, 277484, 278637, 279790, 280943, 282096, 284402, 286708, 289014, 290167, 292473, 293626, 295932, 297085, 298238, 299391, 300544, 301697, 305156, 306309, 309768, 310921, 312074, 313227, 314380, 315533, 316686, 317839, 318992, 320145, 322451, 323604, 325910, 327063, 328216, 330522, 332828, 335134, 336287, 338593, 339746, 342052, 343205, 344358, 345511, 346664, 347817, 351276, 352429, 355888, 357041, 358194, 359347, 360500, 361653, 362806, 363959, 365112, 366265, 368571, 369724, 372030, 373183, 374336, 376642, 377795, 378948, 380101, 381254, 382407, 383560, 384713, 385866, 387019, 388172, 389325, 390478, 391631, 392784, 393937, 395090, 396243, 398549, 399702, 402008, 403161, 404314, 405467, 406620, 407773, 408926, 411232, 412385, 414691, 415844, 416997, 418150, 419303, 420456, 421609, 422762, 423915, 425068, 426221, 427374, 428527, 429680, 430833, 433139, 434292, 435445, 436598, 437751, 438904, 441210, 442363, 443516, 444669, 445822, 446975, 448128, 449281, 450434, 452740, 453893, 455046, 456199, 457352, 458505, 459658, 460811, 461964, 464270, 466576, 467729, 468882, 472723, 473876, 475029, 476182, 479641, 480794, 481947, 484253, 485406, 486559, 487712, 488865, 491171, 492324, 493477, 494630, 495783, 498089, 499242, 500395, 502701, 505007, 506160, 507313, 508466, 509619, 510772, 511925, 516537, 518843, 521149, 522302, 523455, 525761, 528067, 529220, 530373, 531526, 532679, 533832, 534985, 539597, 541903, 543056, 544209, 545362, 546515, 549974, 551127, 552280, 553433, 554586, 555739, 556892, 558045, 559198, 560351, 561504, 562657, 563810, 564963, 568422, 569575, 570728, 571881, 574187, 575340, 576493, 577646, 578799, 579952, 581105, 582258, 583411, 584564, 585717]\n",
      "Lengths between changes: [3841, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 2306, 1153, 1153, 1153, 3459, 1153, 2306, 1153, 2306, 3459, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 3459, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 3459, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 3459, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 3841, 1153, 1153, 1153, 3459, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 3459, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 2306, 2306, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 3459, 1153, 3459, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 2306, 2306, 2306, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 3459, 1153, 3459, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 2306, 1153, 1153, 3841, 1153, 1153, 1153, 3459, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 4612, 2306, 2306, 1153, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 4612, 2306, 1153, 1153, 1153, 1153, 3459, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 3459, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153]\n",
      "Minimum cycle length: 1153\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is defined and already includes an 'event' column\n",
    "# Assuming 'event' column contains class labels\n",
    "event_changes = df['event'].diff().ne(0)\n",
    "change_indices = event_changes[event_changes].index.tolist()\n",
    "\n",
    "# Calculate and print lengths between changes\n",
    "lengths_between_changes = [change_indices[i] - change_indices[i-1] for i in range(1, len(change_indices))]\n",
    "\n",
    "# Find the minimum cycle length where the label changes\n",
    "min_cycle_length = min(lengths_between_changes)\n",
    "\n",
    "print(\"Indices where the 'event' label changes:\", change_indices)\n",
    "print(\"Lengths between changes:\", lengths_between_changes)\n",
    "print(f\"Minimum cycle length: {min_cycle_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_tensor shape: torch.Size([588023, 128])\n",
      "         A1        A2        A3        A4        A5        A6        A7  \\\n",
      "0 -2.488196 -2.276049 -2.513326 -2.187655 -0.665328 -1.345729 -0.058758   \n",
      "1 -2.275978 -2.101950 -2.131188 -2.183079 -0.334046 -0.958461  0.322920   \n",
      "2 -1.464012 -1.438715 -1.267226 -1.501220  0.528039 -0.018531  1.138506   \n",
      "3 -1.288701 -1.256325 -1.333684 -1.322747  0.305930 -0.010463  1.323319   \n",
      "4 -1.962264 -1.981739 -2.139496 -1.853590 -0.356633 -0.631705  0.744775   \n",
      "\n",
      "         A8        A9       A10  ...       D24       D25       D26       D27  \\\n",
      "0  0.063271  0.040405 -1.022892  ... -1.909194 -1.004350 -0.560398 -1.681318   \n",
      "1  0.508570  0.570278 -0.405529  ... -1.421690 -0.624266  0.064576 -0.879298   \n",
      "2  0.803300  0.868933 -0.453136  ... -1.417197  0.003315  1.106200  0.347321   \n",
      "3  0.559827  0.640927 -0.430100  ... -1.310485 -0.432014  0.141858 -0.116593   \n",
      "4  0.204229  0.242720 -0.649710  ... -1.158842 -0.268490  0.383784 -0.470425   \n",
      "\n",
      "        D28       D29       D30       D31       D32  event  \n",
      "0 -1.691767 -1.766298 -0.931525 -1.651438 -1.624403      5  \n",
      "1 -0.971922 -1.347446 -0.658663 -1.326984 -1.307278      5  \n",
      "2  0.198306 -0.831935 -0.626976 -1.237656 -1.236575      5  \n",
      "3 -0.051907 -1.057471 -0.496707 -1.417338 -1.366544      5  \n",
      "4 -0.567732 -1.062428 -0.459739 -1.049760 -1.072294      5  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "segment_pairs = []\n",
    "\n",
    "# Correctly select only the numerical columns (exclude the 'event' column) and convert to a PyTorch tensor\n",
    "df_tensor = torch.tensor(df.iloc[:, :-1].values).float().cuda()  # Using .iloc and .values to correctly handle DataFrame slicing\n",
    "\n",
    "print(\"df_tensor shape:\", df_tensor.shape)\n",
    "# Define a function to perform robust scaling using PyTorch\n",
    "def robust_scale_gpu(data):\n",
    "    median = torch.median(data, dim=0, keepdim=True).values\n",
    "    q75, q25 = torch.quantile(data, torch.tensor([0.75, 0.25], device=data.device), dim=0, keepdim=True)\n",
    "    iqr = q75 - q25\n",
    "\n",
    "    return (data - median) / iqr\n",
    "\n",
    "def standard_scale_gpu(data):\n",
    "    mean = torch.mean(data, dim=0, keepdim=True)\n",
    "    std = torch.std(data, dim=0, keepdim=True)\n",
    "\n",
    "    return (data - mean) / (std + 1e-8)\n",
    "\n",
    "for start, end in zip(change_indices[:-1], change_indices[1:]):\n",
    "    segment_length = end - start\n",
    "    if segment_length >= min_cycle_length and segment_length % min_cycle_length == 0:\n",
    "        # Normalize each sub-segment within the main segment\n",
    "        for offset in range(0, segment_length, min_cycle_length):\n",
    "            sub_start = start + offset\n",
    "            sub_end = sub_start + min_cycle_length\n",
    "            segment = df_tensor[sub_start:sub_end, :]\n",
    "            scaled_segment = standard_scale_gpu(segment)\n",
    "            df_tensor[sub_start:sub_end, :] = scaled_segment  # Correctly place the scaled data back into the DataFrame\n",
    "            segment_pairs.append((sub_start, sub_end))\n",
    "    else:\n",
    "        irregular_num = segment_length//min_cycle_length\n",
    "        # Normalize each sub-segment within the main segment\n",
    "        for i in range(irregular_num):\n",
    "            sub_start = start + i * min_cycle_length\n",
    "            if i == irregular_num - 1:\n",
    "                sub_end = end\n",
    "            else:\n",
    "                sub_end = sub_start + min_cycle_length\n",
    "            segment = df_tensor[sub_start:sub_end, :]\n",
    "            scaled_segment = standard_scale_gpu(segment)\n",
    "            df_tensor[sub_start:sub_end, :] = scaled_segment  # Correctly place the scaled data back into the DataFrame\n",
    "            segment_pairs.append((sub_start, sub_end))\n",
    "# Optionally, convert back to DataFrame if needed for further processing\n",
    "scaled_df = pd.DataFrame(df_tensor.cpu().numpy(), columns=df.columns[:-1])\n",
    "scaled_df['event'] = df['event']\n",
    "num_features = len(scaled_df.columns) - 1\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class EEG_Dataset(Dataset):\n",
    "    def __init__(self, df, indices, max_window_size):\n",
    "        self.df = df\n",
    "        self.indices = indices  # List of start indices\n",
    "        self.max_window_size = max_window_size\n",
    "        self.min_window_size = max_window_size // 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = self.indices[idx]\n",
    "        # Randomly choose a window size between min_window_size and max_window_size\n",
    "        window_size = random.randint(self.min_window_size, self.max_window_size)\n",
    "        \n",
    "        end_idx = start_idx + window_size\n",
    "        # Make sure the end index does not go out of the bounds of the DataFrame\n",
    "        end_idx = min(end_idx, len(self.df))\n",
    "\n",
    "        # Retrieve the sequence using the calculated indices\n",
    "        seq = self.df.iloc[start_idx:end_idx]\n",
    "        X, y = seq.values[:, :-1], seq.values[:, -1]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.long)  # ensure y is a tensor of type long\n",
    "        y = torch.nn.functional.one_hot(y, num_classes=num_classes)  # correct use\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "\n",
    "# Assume 'df' is your DataFrame and 'event' is the column containing labels\n",
    "\n",
    "# Generate indices without mixing segments\n",
    "def generate_indices(input_df, segment_pairs, max_window_size):\n",
    "    indices = []\n",
    "    for start, end in segment_pairs:\n",
    "        max_index = end - max_window_size + 1  # Calculate the maximum starting index for this segment\n",
    "        for i in range(start, max_index):\n",
    "            # Check if all labels in the window are the same\n",
    "            if len(input_df['event'][i:i + max_window_size].unique()) == 1:\n",
    "                indices.append(i)\n",
    "    return indices\n",
    "\n",
    "# Example usage\n",
    "max_window_size = 128\n",
    "indices = generate_indices(scaled_df, segment_pairs, max_window_size)\n",
    "shuffle(indices)  # Shuffle the indices to randomize the data order\n",
    "\n",
    "# Split the indices into training and testing sets\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Assuming you have an EEG_Dataset class defined as before\n",
    "trainset = EEG_Dataset(df=scaled_df, indices=train_indices, max_window_size=max_window_size)\n",
    "testset = EEG_Dataset(df=scaled_df, indices=test_indices, max_window_size=max_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CCNets-team\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from tools.setting.data_config import DataConfig\n",
    "from tools.setting.ml_params import MLParameters\n",
    "from trainer_hub import TrainerHub\n",
    "import torch\n",
    "\n",
    "data_config = DataConfig(dataset_name = 'eeg-sub-01', task_type='multi_class_classification', obs_shape=[num_features], label_size=num_classes)\n",
    "\n",
    "#  Set training configuration from the AlgorithmConfig class, returning them as a Namespace object.\n",
    "ml_params = MLParameters(core_model = 'gpt', encoder_model = 'none')\n",
    "\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Initialize the TrainerHub class with the training configuration, data configuration, device, and use_print and use_wandb flags\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device, use_print=True, use_wandb=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd9bcb916ee479ca9bf37eb84ceb9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][50/6516][Time 19.37]\n",
      "Unified LR across all optimizers: 0.0001995308238189185\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.3349\tGen: 0.6791\tRec: 0.6165\tE: 0.3969\tR: 0.2717\tP: 0.9631\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.0862\n",
      "precision: 0.1546\n",
      "recall: 0.0771\n",
      "f1_score: 0.0243\n",
      "\n",
      "[0/100][100/6516][Time 18.29]\n",
      "Unified LR across all optimizers: 0.00019907191565870155\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.1614\tGen: 0.4753\tRec: 0.4492\tE: 0.1878\tR: 0.1355\tP: 0.7630\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.1120\n",
      "precision: 0.0651\n",
      "recall: 0.0877\n",
      "f1_score: 0.0384\n",
      "\n",
      "[0/100][150/6516][Time 18.15]\n",
      "Unified LR across all optimizers: 0.00019861406295796434\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.1353\tGen: 0.4374\tRec: 0.4186\tE: 0.1542\tR: 0.1166\tP: 0.7217\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.1354\n",
      "precision: 0.1131\n",
      "recall: 0.1161\n",
      "f1_score: 0.0755\n",
      "\n",
      "[0/100][200/6516][Time 18.16]\n",
      "Unified LR across all optimizers: 0.00019815726328921765\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.1337\tGen: 0.4149\tRec: 0.3956\tE: 0.1533\tR: 0.1149\tP: 0.6781\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.2092\n",
      "precision: 0.1090\n",
      "recall: 0.1378\n",
      "f1_score: 0.0946\n",
      "\n",
      "[0/100][250/6516][Time 18.30]\n",
      "Unified LR across all optimizers: 0.00019770151423055492\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.1285\tGen: 0.3947\tRec: 0.3770\tE: 0.1468\tR: 0.1111\tP: 0.6434\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.3941\n",
      "precision: 0.2380\n",
      "recall: 0.2398\n",
      "f1_score: 0.1928\n",
      "\n",
      "[0/100][300/6516][Time 18.25]\n",
      "Unified LR across all optimizers: 0.00019724681336564005\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.1169\tGen: 0.3807\tRec: 0.3665\tE: 0.1312\tR: 0.1027\tP: 0.6311\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.3247\n",
      "precision: 0.2464\n",
      "recall: 0.3070\n",
      "f1_score: 0.2149\n",
      "\n",
      "[0/100][350/6516][Time 18.30]\n",
      "Unified LR across all optimizers: 0.00019679315828369438\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.1077\tGen: 0.3670\tRec: 0.3551\tE: 0.1199\tR: 0.0959\tP: 0.6151\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.2602\n",
      "precision: 0.2332\n",
      "recall: 0.2088\n",
      "f1_score: 0.1534\n",
      "\n",
      "[0/100][400/6516][Time 18.33]\n",
      "Unified LR across all optimizers: 0.00019634054657948372\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0988\tGen: 0.3593\tRec: 0.3489\tE: 0.1085\tR: 0.0877\tP: 0.6127\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.2857\n",
      "precision: 0.2904\n",
      "recall: 0.2747\n",
      "f1_score: 0.2057\n",
      "\n",
      "[0/100][450/6516][Time 18.32]\n",
      "Unified LR across all optimizers: 0.00019588897585330582\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0965\tGen: 0.3542\tRec: 0.3440\tE: 0.1067\tR: 0.0859\tP: 0.6039\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.4299\n",
      "precision: 0.2780\n",
      "recall: 0.3113\n",
      "f1_score: 0.2526\n",
      "\n",
      "[0/100][500/6516][Time 18.30]\n",
      "Unified LR across all optimizers: 0.00019543844371097777\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0909\tGen: 0.3453\tRec: 0.3359\tE: 0.0995\tR: 0.0808\tP: 0.5925\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.3521\n",
      "precision: 0.3649\n",
      "recall: 0.3297\n",
      "f1_score: 0.2514\n",
      "\n",
      "[0/100][550/6516][Time 18.32]\n",
      "Unified LR across all optimizers: 0.00019498894776382288\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0846\tGen: 0.3366\tRec: 0.3279\tE: 0.0925\tR: 0.0751\tP: 0.5823\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.3924\n",
      "precision: 0.2638\n",
      "recall: 0.2961\n",
      "f1_score: 0.2546\n",
      "\n",
      "[0/100][600/6516][Time 18.34]\n",
      "Unified LR across all optimizers: 0.00019454048562865856\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0825\tGen: 0.3315\tRec: 0.3231\tE: 0.0901\tR: 0.0729\tP: 0.5738\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.4969\n",
      "precision: 0.3377\n",
      "recall: 0.4440\n",
      "f1_score: 0.3548\n",
      "\n",
      "[0/100][650/6516][Time 18.34]\n",
      "Unified LR across all optimizers: 0.00019409305492778308\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0763\tGen: 0.3270\tRec: 0.3194\tE: 0.0823\tR: 0.0669\tP: 0.5726\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.4519\n",
      "precision: 0.3036\n",
      "recall: 0.3854\n",
      "f1_score: 0.3067\n",
      "\n",
      "[0/100][700/6516][Time 18.28]\n",
      "Unified LR across all optimizers: 0.00019364665328896346\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0736\tGen: 0.3223\tRec: 0.3150\tE: 0.0802\tR: 0.0654\tP: 0.5659\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5610\n",
      "precision: 0.4220\n",
      "recall: 0.4486\n",
      "f1_score: 0.3847\n",
      "\n",
      "[0/100][750/6516][Time 18.59]\n",
      "Unified LR across all optimizers: 0.00019320127834542263\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0703\tGen: 0.3185\tRec: 0.3114\tE: 0.0764\tR: 0.0621\tP: 0.5604\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5102\n",
      "precision: 0.4315\n",
      "recall: 0.4522\n",
      "f1_score: 0.4221\n",
      "\n",
      "[0/100][800/6516][Time 18.17]\n",
      "Unified LR across all optimizers: 0.00019275692773582703\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0655\tGen: 0.3121\tRec: 0.3061\tE: 0.0703\tR: 0.0583\tP: 0.5544\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7184\n",
      "precision: 0.4730\n",
      "recall: 0.5127\n",
      "f1_score: 0.4586\n",
      "\n",
      "[0/100][850/6516][Time 18.06]\n",
      "Unified LR across all optimizers: 0.0001923135991042739\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0636\tGen: 0.3084\tRec: 0.3027\tE: 0.0679\tR: 0.0564\tP: 0.5494\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6210\n",
      "precision: 0.4225\n",
      "recall: 0.4900\n",
      "f1_score: 0.4433\n",
      "\n",
      "[0/100][900/6516][Time 17.57]\n",
      "Unified LR across all optimizers: 0.0001918712901002789\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0600\tGen: 0.3070\tRec: 0.3021\tE: 0.0631\tR: 0.0530\tP: 0.5518\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6992\n",
      "precision: 0.4264\n",
      "recall: 0.5072\n",
      "f1_score: 0.4548\n",
      "\n",
      "[0/100][950/6516][Time 17.53]\n",
      "Unified LR across all optimizers: 0.00019142999837876384\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0593\tGen: 0.2996\tRec: 0.2945\tE: 0.0632\tR: 0.0528\tP: 0.5367\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5416\n",
      "precision: 0.3842\n",
      "recall: 0.4461\n",
      "f1_score: 0.4045\n",
      "\n",
      "[0/100][1000/6516][Time 17.56]\n",
      "Unified LR across all optimizers: 0.00019098972160004388\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0568\tGen: 0.2973\tRec: 0.2927\tE: 0.0601\tR: 0.0505\tP: 0.5353\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5064\n",
      "precision: 0.3816\n",
      "recall: 0.5003\n",
      "f1_score: 0.4205\n",
      "\n",
      "[0/100][1050/6516][Time 17.47]\n",
      "Unified LR across all optimizers: 0.00019055045742981543\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0525\tGen: 0.2945\tRec: 0.2906\tE: 0.0542\tR: 0.0464\tP: 0.5367\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5642\n",
      "precision: 0.5455\n",
      "recall: 0.5794\n",
      "f1_score: 0.4938\n",
      "\n",
      "[0/100][1100/6516][Time 17.96]\n",
      "Unified LR across all optimizers: 0.00019011220353914353\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0508\tGen: 0.2905\tRec: 0.2868\tE: 0.0525\tR: 0.0449\tP: 0.5294\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5974\n",
      "precision: 0.5143\n",
      "recall: 0.6222\n",
      "f1_score: 0.5111\n",
      "\n",
      "[0/100][1150/6516][Time 18.14]\n",
      "Unified LR across all optimizers: 0.00018967495760444968\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0472\tGen: 0.2866\tRec: 0.2834\tE: 0.0482\tR: 0.0416\tP: 0.5251\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7642\n",
      "precision: 0.5529\n",
      "recall: 0.5920\n",
      "f1_score: 0.5616\n",
      "\n",
      "[0/100][1200/6516][Time 17.49]\n",
      "Unified LR across all optimizers: 0.00018923871730749947\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0467\tGen: 0.2842\tRec: 0.2811\tE: 0.0483\tR: 0.0419\tP: 0.5207\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7124\n",
      "precision: 0.4385\n",
      "recall: 0.5536\n",
      "f1_score: 0.4835\n",
      "\n",
      "[0/100][1250/6516][Time 17.53]\n",
      "Unified LR across all optimizers: 0.00018880348033539028\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0461\tGen: 0.2820\tRec: 0.2790\tE: 0.0484\tR: 0.0418\tP: 0.5170\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7918\n",
      "precision: 0.5597\n",
      "recall: 0.6144\n",
      "f1_score: 0.5781\n",
      "\n",
      "[0/100][1300/6516][Time 17.52]\n",
      "Unified LR across all optimizers: 0.00018836924438053897\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0432\tGen: 0.2807\tRec: 0.2783\tE: 0.0439\tR: 0.0388\tP: 0.5191\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6708\n",
      "precision: 0.5721\n",
      "recall: 0.6244\n",
      "f1_score: 0.5642\n",
      "\n",
      "[0/100][1350/6516][Time 17.45]\n",
      "Unified LR across all optimizers: 0.0001879360071406698\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0417\tGen: 0.2777\tRec: 0.2756\tE: 0.0418\tR: 0.0376\tP: 0.5144\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7297\n",
      "precision: 0.5816\n",
      "recall: 0.6309\n",
      "f1_score: 0.5905\n",
      "\n",
      "[0/100][1400/6516][Time 17.47]\n",
      "Unified LR across all optimizers: 0.000187503766318802\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0419\tGen: 0.2735\tRec: 0.2712\tE: 0.0425\tR: 0.0377\tP: 0.5052\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8134\n",
      "precision: 0.6003\n",
      "recall: 0.6669\n",
      "f1_score: 0.6243\n",
      "\n",
      "[0/100][1450/6516][Time 18.35]\n",
      "Unified LR across all optimizers: 0.00018707251962323787\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0383\tGen: 0.2712\tRec: 0.2693\tE: 0.0385\tR: 0.0344\tP: 0.5043\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6806\n",
      "precision: 0.4867\n",
      "recall: 0.5957\n",
      "f1_score: 0.5132\n",
      "\n",
      "[0/100][1500/6516][Time 17.84]\n",
      "Unified LR across all optimizers: 0.0001866422647675502\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0371\tGen: 0.2677\tRec: 0.2660\tE: 0.0374\tR: 0.0338\tP: 0.4996\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8399\n",
      "precision: 0.7058\n",
      "recall: 0.7016\n",
      "f1_score: 0.6917\n",
      "\n",
      "[0/100][1550/6516][Time 17.48]\n",
      "Unified LR across all optimizers: 0.00018621299947057073\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0346\tGen: 0.2652\tRec: 0.2633\tE: 0.0343\tR: 0.0305\tP: 0.4967\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7385\n",
      "precision: 0.4928\n",
      "recall: 0.5910\n",
      "f1_score: 0.5174\n",
      "\n",
      "[0/100][1600/6516][Time 17.51]\n",
      "Unified LR across all optimizers: 0.00018578472145637737\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0348\tGen: 0.2657\tRec: 0.2641\tE: 0.0348\tR: 0.0314\tP: 0.4987\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7488\n",
      "precision: 0.5861\n",
      "recall: 0.6993\n",
      "f1_score: 0.6289\n",
      "\n",
      "[0/100][1650/6516][Time 17.54]\n",
      "Unified LR across all optimizers: 0.00018535742845428288\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0326\tGen: 0.2634\tRec: 0.2621\tE: 0.0314\tR: 0.0288\tP: 0.4963\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7550\n",
      "precision: 0.6085\n",
      "recall: 0.6568\n",
      "f1_score: 0.6151\n",
      "\n",
      "[0/100][1700/6516][Time 17.50]\n",
      "Unified LR across all optimizers: 0.00018493111819882223\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0332\tGen: 0.2585\tRec: 0.2570\tE: 0.0327\tR: 0.0295\tP: 0.4867\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7588\n",
      "precision: 0.5925\n",
      "recall: 0.6748\n",
      "f1_score: 0.6180\n",
      "\n",
      "[0/100][1750/6516][Time 17.49]\n",
      "Unified LR across all optimizers: 0.00018450578842974107\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0336\tGen: 0.2585\tRec: 0.2570\tE: 0.0332\tR: 0.0300\tP: 0.4852\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7758\n",
      "precision: 0.6723\n",
      "recall: 0.6524\n",
      "f1_score: 0.6283\n",
      "\n",
      "[0/100][1800/6516][Time 17.48]\n",
      "Unified LR across all optimizers: 0.00018408143689198318\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0315\tGen: 0.2553\tRec: 0.2538\tE: 0.0312\tR: 0.0281\tP: 0.4809\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8018\n",
      "precision: 0.6292\n",
      "recall: 0.7082\n",
      "f1_score: 0.6504\n",
      "\n",
      "[0/100][1850/6516][Time 17.49]\n",
      "Unified LR across all optimizers: 0.0001836580613356789\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0293\tGen: 0.2543\tRec: 0.2533\tE: 0.0291\tR: 0.0267\tP: 0.4818\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8223\n",
      "precision: 0.5803\n",
      "recall: 0.6365\n",
      "f1_score: 0.5947\n",
      "\n",
      "[0/100][1900/6516][Time 17.49]\n",
      "Unified LR across all optimizers: 0.0001832356595161332\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0294\tGen: 0.2514\tRec: 0.2499\tE: 0.0295\tR: 0.0265\tP: 0.4748\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8166\n",
      "precision: 0.5930\n",
      "recall: 0.5809\n",
      "f1_score: 0.5591\n",
      "\n",
      "[0/100][1950/6516][Time 17.55]\n",
      "Unified LR across all optimizers: 0.00018281422919381367\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0286\tGen: 0.2511\tRec: 0.2501\tE: 0.0277\tR: 0.0255\tP: 0.4759\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8258\n",
      "precision: 0.5886\n",
      "recall: 0.6471\n",
      "f1_score: 0.6114\n",
      "\n",
      "[0/100][2000/6516][Time 17.46]\n",
      "Unified LR across all optimizers: 0.00018239376813433867\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0282\tGen: 0.2470\tRec: 0.2462\tE: 0.0274\tR: 0.0254\tP: 0.4683\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7666\n",
      "precision: 0.6861\n",
      "recall: 0.7235\n",
      "f1_score: 0.6840\n",
      "\n",
      "[0/100][2050/6516][Time 17.49]\n",
      "Unified LR across all optimizers: 0.00018197427410846564\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0262\tGen: 0.2448\tRec: 0.2441\tE: 0.0251\tR: 0.0237\tP: 0.4662\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8542\n",
      "precision: 0.7476\n",
      "recall: 0.7728\n",
      "f1_score: 0.7489\n",
      "\n",
      "[0/100][2100/6516][Time 17.48]\n",
      "Unified LR across all optimizers: 0.00018155574489207887\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0246\tGen: 0.2437\tRec: 0.2428\tE: 0.0232\tR: 0.0214\tP: 0.4657\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8344\n",
      "precision: 0.6703\n",
      "recall: 0.7619\n",
      "f1_score: 0.7020\n",
      "\n",
      "[0/100][2150/6516][Time 18.54]\n",
      "Unified LR across all optimizers: 0.00018113817826617823\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0265\tGen: 0.2416\tRec: 0.2407\tE: 0.0259\tR: 0.0239\tP: 0.4589\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8937\n",
      "precision: 0.6397\n",
      "recall: 0.6878\n",
      "f1_score: 0.6583\n",
      "\n",
      "[0/100][2200/6516][Time 17.75]\n",
      "Unified LR across all optimizers: 0.00018072157201686696\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0253\tGen: 0.2405\tRec: 0.2398\tE: 0.0243\tR: 0.0228\tP: 0.4587\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9010\n",
      "precision: 0.7304\n",
      "recall: 0.7197\n",
      "f1_score: 0.7241\n",
      "\n",
      "[0/100][2250/6516][Time 17.49]\n",
      "Unified LR across all optimizers: 0.00018030592393534033\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0240\tGen: 0.2381\tRec: 0.2374\tE: 0.0229\tR: 0.0213\tP: 0.4544\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8723\n",
      "precision: 0.6554\n",
      "recall: 0.6660\n",
      "f1_score: 0.6390\n",
      "\n",
      "[0/100][2300/6516][Time 18.19]\n",
      "Unified LR across all optimizers: 0.0001798912318178735\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0228\tGen: 0.2355\tRec: 0.2348\tE: 0.0215\tR: 0.0199\tP: 0.4516\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8588\n",
      "precision: 0.7322\n",
      "recall: 0.7629\n",
      "f1_score: 0.7396\n",
      "\n",
      "[0/100][2350/6516][Time 18.43]\n",
      "Unified LR across all optimizers: 0.00017947749346581006\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0212\tGen: 0.2321\tRec: 0.2318\tE: 0.0189\tR: 0.0182\tP: 0.4473\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8717\n",
      "precision: 0.7251\n",
      "recall: 0.7640\n",
      "f1_score: 0.7433\n",
      "\n",
      "[0/100][2400/6516][Time 18.27]\n",
      "Unified LR across all optimizers: 0.0001790647066855505\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0199\tGen: 0.2300\tRec: 0.2298\tE: 0.0186\tR: 0.0178\tP: 0.4423\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8486\n",
      "precision: 0.7161\n",
      "recall: 0.7807\n",
      "f1_score: 0.7363\n",
      "\n",
      "[0/100][2450/6516][Time 18.85]\n",
      "Unified LR across all optimizers: 0.00017865286928854052\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0220\tGen: 0.2280\tRec: 0.2277\tE: 0.0209\tR: 0.0202\tP: 0.4372\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8412\n",
      "precision: 0.7222\n",
      "recall: 0.7791\n",
      "f1_score: 0.7470\n",
      "\n",
      "[0/100][2500/6516][Time 18.34]\n",
      "Unified LR across all optimizers: 0.00017824197909125899\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0195\tGen: 0.2275\tRec: 0.2273\tE: 0.0179\tR: 0.0172\tP: 0.4385\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9165\n",
      "precision: 0.7695\n",
      "recall: 0.8060\n",
      "f1_score: 0.7801\n",
      "\n",
      "[0/100][2550/6516][Time 18.37]\n",
      "Unified LR across all optimizers: 0.00017783203391520723\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0190\tGen: 0.2261\tRec: 0.2257\tE: 0.0177\tR: 0.0168\tP: 0.4356\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8530\n",
      "precision: 0.6784\n",
      "recall: 0.6804\n",
      "f1_score: 0.6584\n",
      "\n",
      "[0/100][2600/6516][Time 18.14]\n",
      "Unified LR across all optimizers: 0.00017742303158689668\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0186\tGen: 0.2224\tRec: 0.2221\tE: 0.0173\tR: 0.0166\tP: 0.4292\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9210\n",
      "precision: 0.7984\n",
      "recall: 0.8110\n",
      "f1_score: 0.8028\n",
      "\n",
      "[0/100][2650/6516][Time 17.89]\n",
      "Unified LR across all optimizers: 0.00017701496993783762\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0184\tGen: 0.2201\tRec: 0.2197\tE: 0.0170\tR: 0.0160\tP: 0.4246\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8483\n",
      "precision: 0.6761\n",
      "recall: 0.7246\n",
      "f1_score: 0.6934\n",
      "\n",
      "[0/100][2700/6516][Time 18.35]\n",
      "Unified LR across all optimizers: 0.00017660784680452796\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0170\tGen: 0.2185\tRec: 0.2183\tE: 0.0153\tR: 0.0147\tP: 0.4236\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8941\n",
      "precision: 0.7318\n",
      "recall: 0.7742\n",
      "f1_score: 0.7455\n",
      "\n",
      "[0/100][2750/6516][Time 17.84]\n",
      "Unified LR across all optimizers: 0.0001762016600284412\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0174\tGen: 0.2174\tRec: 0.2173\tE: 0.0163\tR: 0.0157\tP: 0.4200\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8640\n",
      "precision: 0.7536\n",
      "recall: 0.7889\n",
      "f1_score: 0.7624\n",
      "\n",
      "[0/100][2800/6516][Time 17.98]\n",
      "Unified LR across all optimizers: 0.00017579640745601563\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0166\tGen: 0.2153\tRec: 0.2153\tE: 0.0149\tR: 0.0147\tP: 0.4171\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9333\n",
      "precision: 0.7973\n",
      "recall: 0.8081\n",
      "f1_score: 0.8019\n",
      "\n",
      "[0/100][2850/6516][Time 18.90]\n",
      "Unified LR across all optimizers: 0.0001753920869386423\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0169\tGen: 0.2133\tRec: 0.2131\tE: 0.0158\tR: 0.0151\tP: 0.4131\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9054\n",
      "precision: 0.7784\n",
      "recall: 0.7518\n",
      "f1_score: 0.7544\n",
      "\n",
      "[0/100][2900/6516][Time 18.59]\n",
      "Unified LR across all optimizers: 0.0001749886963326542\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0170\tGen: 0.2126\tRec: 0.2126\tE: 0.0154\tR: 0.0151\tP: 0.4117\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9057\n",
      "precision: 0.7270\n",
      "recall: 0.7450\n",
      "f1_score: 0.7333\n",
      "\n",
      "[0/100][2950/6516][Time 18.38]\n",
      "Unified LR across all optimizers: 0.0001745862334993144\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0162\tGen: 0.2101\tRec: 0.2100\tE: 0.0148\tR: 0.0144\tP: 0.4071\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9311\n",
      "precision: 0.7884\n",
      "recall: 0.8144\n",
      "f1_score: 0.7984\n",
      "\n",
      "[0/100][3000/6516][Time 17.77]\n",
      "Unified LR across all optimizers: 0.00017418469630480507\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0163\tGen: 0.2081\tRec: 0.2079\tE: 0.0147\tR: 0.0143\tP: 0.4028\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8762\n",
      "precision: 0.6825\n",
      "recall: 0.7359\n",
      "f1_score: 0.7050\n",
      "\n",
      "[0/100][3050/6516][Time 17.75]\n",
      "Unified LR across all optimizers: 0.00017378408262021616\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0160\tGen: 0.2080\tRec: 0.2080\tE: 0.0143\tR: 0.0141\tP: 0.4034\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9025\n",
      "precision: 0.7767\n",
      "recall: 0.8081\n",
      "f1_score: 0.7896\n",
      "\n",
      "[0/100][3100/6516][Time 17.77]\n",
      "Unified LR across all optimizers: 0.00017338439032153356\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0159\tGen: 0.2060\tRec: 0.2059\tE: 0.0148\tR: 0.0143\tP: 0.3991\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8889\n",
      "precision: 0.7311\n",
      "recall: 0.7379\n",
      "f1_score: 0.7201\n",
      "\n",
      "[0/100][3150/6516][Time 17.74]\n",
      "Unified LR across all optimizers: 0.00017298561728962847\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0156\tGen: 0.2045\tRec: 0.2047\tE: 0.0136\tR: 0.0137\tP: 0.3965\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8943\n",
      "precision: 0.7667\n",
      "recall: 0.7511\n",
      "f1_score: 0.7421\n",
      "\n",
      "[0/100][3200/6516][Time 17.74]\n",
      "Unified LR across all optimizers: 0.00017258776141024598\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0151\tGen: 0.2035\tRec: 0.2038\tE: 0.0129\tR: 0.0131\tP: 0.3956\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9295\n",
      "precision: 0.7334\n",
      "recall: 0.7409\n",
      "f1_score: 0.7342\n",
      "\n",
      "[0/100][3250/6516][Time 17.73]\n",
      "Unified LR across all optimizers: 0.00017219082057399394\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0135\tGen: 0.2018\tRec: 0.2022\tE: 0.0111\tR: 0.0116\tP: 0.3942\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8828\n",
      "precision: 0.7544\n",
      "recall: 0.7094\n",
      "f1_score: 0.7058\n",
      "\n",
      "[0/100][3300/6516][Time 17.77]\n",
      "Unified LR across all optimizers: 0.00017179479267633146\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0134\tGen: 0.2011\tRec: 0.2013\tE: 0.0116\tR: 0.0119\tP: 0.3923\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9399\n",
      "precision: 0.8569\n",
      "recall: 0.8551\n",
      "f1_score: 0.8554\n",
      "\n",
      "[0/100][3350/6516][Time 17.77]\n",
      "Unified LR across all optimizers: 0.00017139967561755819\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0117\tGen: 0.1987\tRec: 0.1992\tE: 0.0096\tR: 0.0103\tP: 0.3896\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9162\n",
      "precision: 0.7580\n",
      "recall: 0.7543\n",
      "f1_score: 0.7455\n",
      "\n",
      "[0/100][3400/6516][Time 17.75]\n",
      "Unified LR across all optimizers: 0.00017100546730280274\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0127\tGen: 0.1991\tRec: 0.1995\tE: 0.0107\tR: 0.0112\tP: 0.3886\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9409\n",
      "precision: 0.7815\n",
      "recall: 0.7852\n",
      "f1_score: 0.7749\n",
      "\n",
      "[0/100][3450/6516][Time 18.22]\n",
      "Unified LR across all optimizers: 0.00017061216564201177\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0123\tGen: 0.1968\tRec: 0.1973\tE: 0.0101\tR: 0.0109\tP: 0.3854\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9013\n",
      "precision: 0.8532\n",
      "recall: 0.8123\n",
      "f1_score: 0.8204\n",
      "\n",
      "[0/100][3500/6516][Time 18.47]\n",
      "Unified LR across all optimizers: 0.0001702197685499392\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0110\tGen: 0.1958\tRec: 0.1963\tE: 0.0090\tR: 0.0099\tP: 0.3841\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9418\n",
      "precision: 0.8687\n",
      "recall: 0.8791\n",
      "f1_score: 0.8705\n",
      "\n",
      "[0/100][3550/6516][Time 18.27]\n",
      "Unified LR across all optimizers: 0.0001698282739461345\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0109\tGen: 0.1928\tRec: 0.1933\tE: 0.0088\tR: 0.0095\tP: 0.3783\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8474\n",
      "precision: 0.7196\n",
      "recall: 0.7121\n",
      "f1_score: 0.6853\n",
      "\n",
      "[0/100][3600/6516][Time 18.34]\n",
      "Unified LR across all optimizers: 0.00016943767975493242\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0103\tGen: 0.1920\tRec: 0.1925\tE: 0.0083\tR: 0.0091\tP: 0.3775\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9505\n",
      "precision: 0.8805\n",
      "recall: 0.8777\n",
      "f1_score: 0.8771\n",
      "\n",
      "[0/100][3650/6516][Time 17.72]\n",
      "Unified LR across all optimizers: 0.0001690479839054414\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0095\tGen: 0.1914\tRec: 0.1920\tE: 0.0075\tR: 0.0083\tP: 0.3777\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9191\n",
      "precision: 0.8390\n",
      "recall: 0.8407\n",
      "f1_score: 0.8330\n",
      "\n",
      "[0/100][3700/6516][Time 18.59]\n",
      "Unified LR across all optimizers: 0.00016865918433153277\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0094\tGen: 0.1894\tRec: 0.1899\tE: 0.0073\tR: 0.0079\tP: 0.3730\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9384\n",
      "precision: 0.7245\n",
      "recall: 0.7134\n",
      "f1_score: 0.7067\n",
      "\n",
      "[0/100][3750/6516][Time 17.98]\n",
      "Unified LR across all optimizers: 0.00016827127897182985\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0090\tGen: 0.1889\tRec: 0.1894\tE: 0.0069\tR: 0.0077\tP: 0.3722\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9143\n",
      "precision: 0.8431\n",
      "recall: 0.8283\n",
      "f1_score: 0.8299\n",
      "\n",
      "[0/100][3800/6516][Time 17.79]\n",
      "Unified LR across all optimizers: 0.0001678842657696972\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0083\tGen: 0.1857\tRec: 0.1863\tE: 0.0064\tR: 0.0072\tP: 0.3663\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9298\n",
      "precision: 0.8740\n",
      "recall: 0.8556\n",
      "f1_score: 0.8484\n",
      "\n",
      "[0/100][3850/6516][Time 17.77]\n",
      "Unified LR across all optimizers: 0.00016749814267322938\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0080\tGen: 0.1857\tRec: 0.1863\tE: 0.0059\tR: 0.0068\tP: 0.3671\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9431\n",
      "precision: 0.8792\n",
      "recall: 0.8590\n",
      "f1_score: 0.8657\n",
      "\n",
      "[0/100][3900/6516][Time 18.65]\n",
      "Unified LR across all optimizers: 0.00016711290763524007\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0082\tGen: 0.1852\tRec: 0.1858\tE: 0.0062\tR: 0.0073\tP: 0.3654\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9452\n",
      "precision: 0.8111\n",
      "recall: 0.8190\n",
      "f1_score: 0.8124\n",
      "\n",
      "[0/100][3950/6516][Time 18.20]\n",
      "Unified LR across all optimizers: 0.00016672855861325146\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0086\tGen: 0.1825\tRec: 0.1832\tE: 0.0067\tR: 0.0077\tP: 0.3592\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9168\n",
      "precision: 0.7739\n",
      "recall: 0.7673\n",
      "f1_score: 0.7594\n",
      "\n",
      "[0/100][4000/6516][Time 18.36]\n",
      "Unified LR across all optimizers: 0.00016634509356948314\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0077\tGen: 0.1823\tRec: 0.1828\tE: 0.0058\tR: 0.0067\tP: 0.3604\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9481\n",
      "precision: 0.8732\n",
      "recall: 0.8582\n",
      "f1_score: 0.8584\n",
      "\n",
      "[0/100][4050/6516][Time 17.88]\n",
      "Unified LR across all optimizers: 0.00016596251047084197\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0072\tGen: 0.1800\tRec: 0.1806\tE: 0.0053\tR: 0.0062\tP: 0.3566\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9560\n",
      "precision: 0.8669\n",
      "recall: 0.8911\n",
      "f1_score: 0.8757\n",
      "\n",
      "[0/100][4100/6516][Time 18.42]\n",
      "Unified LR across all optimizers: 0.00016558080728890993\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0071\tGen: 0.1793\tRec: 0.1798\tE: 0.0052\tR: 0.0060\tP: 0.3550\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9249\n",
      "precision: 0.8679\n",
      "recall: 0.8651\n",
      "f1_score: 0.8590\n",
      "\n",
      "[0/100][4150/6516][Time 18.07]\n",
      "Unified LR across all optimizers: 0.00016519998199993532\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0073\tGen: 0.1787\tRec: 0.1792\tE: 0.0055\tR: 0.0063\tP: 0.3532\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9430\n",
      "precision: 0.8016\n",
      "recall: 0.8048\n",
      "f1_score: 0.8019\n",
      "\n",
      "[0/100][4200/6516][Time 17.99]\n",
      "Unified LR across all optimizers: 0.0001648200325848201\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0070\tGen: 0.1767\tRec: 0.1772\tE: 0.0052\tR: 0.0060\tP: 0.3499\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9573\n",
      "precision: 0.8790\n",
      "recall: 0.8831\n",
      "f1_score: 0.8800\n",
      "\n",
      "[0/100][4250/6516][Time 18.28]\n",
      "Unified LR across all optimizers: 0.00016444095702911038\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0069\tGen: 0.1766\tRec: 0.1771\tE: 0.0051\tR: 0.0059\tP: 0.3499\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9802\n",
      "precision: 0.9023\n",
      "recall: 0.9141\n",
      "f1_score: 0.9077\n",
      "\n",
      "[0/100][4300/6516][Time 17.97]\n",
      "Unified LR across all optimizers: 0.00016406275332298505\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0069\tGen: 0.1762\tRec: 0.1767\tE: 0.0050\tR: 0.0059\tP: 0.3497\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9533\n",
      "precision: 0.8942\n",
      "recall: 0.8920\n",
      "f1_score: 0.8920\n",
      "\n",
      "[0/100][4350/6516][Time 17.80]\n",
      "Unified LR across all optimizers: 0.00016368541946124596\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0060\tGen: 0.1734\tRec: 0.1738\tE: 0.0045\tR: 0.0052\tP: 0.3441\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9590\n",
      "precision: 0.8869\n",
      "recall: 0.8886\n",
      "f1_score: 0.8867\n",
      "\n",
      "[0/100][4400/6516][Time 17.88]\n",
      "Unified LR across all optimizers: 0.00016330895344330638\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0061\tGen: 0.1724\tRec: 0.1729\tE: 0.0045\tR: 0.0054\tP: 0.3418\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9565\n",
      "precision: 0.8647\n",
      "recall: 0.8698\n",
      "f1_score: 0.8665\n",
      "\n",
      "[0/100][4450/6516][Time 18.31]\n",
      "Unified LR across all optimizers: 0.00016293335327318117\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0061\tGen: 0.1717\tRec: 0.1723\tE: 0.0044\tR: 0.0052\tP: 0.3409\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9546\n",
      "precision: 0.8811\n",
      "recall: 0.8966\n",
      "f1_score: 0.8879\n",
      "\n",
      "[0/100][4500/6516][Time 18.53]\n",
      "Unified LR across all optimizers: 0.00016255861695947546\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0062\tGen: 0.1707\tRec: 0.1712\tE: 0.0046\tR: 0.0054\tP: 0.3378\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9687\n",
      "precision: 0.8332\n",
      "recall: 0.8309\n",
      "f1_score: 0.8318\n",
      "\n",
      "[0/100][4550/6516][Time 18.34]\n",
      "Unified LR across all optimizers: 0.00016218474251537463\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0060\tGen: 0.1703\tRec: 0.1708\tE: 0.0043\tR: 0.0050\tP: 0.3384\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9623\n",
      "precision: 0.8935\n",
      "recall: 0.8967\n",
      "f1_score: 0.8942\n",
      "\n",
      "[0/100][4600/6516][Time 18.35]\n",
      "Unified LR across all optimizers: 0.00016181172795863357\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0056\tGen: 0.1685\tRec: 0.1691\tE: 0.0039\tR: 0.0047\tP: 0.3345\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9581\n",
      "precision: 0.8229\n",
      "recall: 0.8045\n",
      "f1_score: 0.8107\n",
      "\n",
      "[0/100][4650/6516][Time 18.31]\n",
      "Unified LR across all optimizers: 0.0001614395713115662\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0059\tGen: 0.1681\tRec: 0.1686\tE: 0.0043\tR: 0.0052\tP: 0.3327\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9494\n",
      "precision: 0.8873\n",
      "recall: 0.8811\n",
      "f1_score: 0.8828\n",
      "\n",
      "[0/100][4700/6516][Time 18.33]\n",
      "Unified LR across all optimizers: 0.00016106827060103523\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0060\tGen: 0.1667\tRec: 0.1673\tE: 0.0043\tR: 0.0052\tP: 0.3306\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9674\n",
      "precision: 0.8069\n",
      "recall: 0.8203\n",
      "f1_score: 0.8124\n",
      "\n",
      "[0/100][4750/6516][Time 18.35]\n",
      "Unified LR across all optimizers: 0.00016069782385844109\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0059\tGen: 0.1654\tRec: 0.1660\tE: 0.0043\tR: 0.0052\tP: 0.3285\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9733\n",
      "precision: 0.8280\n",
      "recall: 0.8420\n",
      "f1_score: 0.8342\n",
      "\n",
      "[0/100][4800/6516][Time 18.04]\n",
      "Unified LR across all optimizers: 0.00016032822911971208\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0056\tGen: 0.1651\tRec: 0.1657\tE: 0.0039\tR: 0.0049\tP: 0.3284\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9750\n",
      "precision: 0.9077\n",
      "recall: 0.9072\n",
      "f1_score: 0.9071\n",
      "\n",
      "[0/100][4850/6516][Time 18.60]\n",
      "Unified LR across all optimizers: 0.0001599594844252937\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0053\tGen: 0.1637\tRec: 0.1643\tE: 0.0038\tR: 0.0046\tP: 0.3257\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9374\n",
      "precision: 0.8048\n",
      "recall: 0.7999\n",
      "f1_score: 0.7991\n",
      "\n",
      "[0/100][4900/6516][Time 18.45]\n",
      "Unified LR across all optimizers: 0.00015959158782013816\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0049\tGen: 0.1628\tRec: 0.1633\tE: 0.0034\tR: 0.0041\tP: 0.3249\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9676\n",
      "precision: 0.8305\n",
      "recall: 0.8308\n",
      "f1_score: 0.8304\n",
      "\n",
      "[0/100][4950/6516][Time 17.88]\n",
      "Unified LR across all optimizers: 0.00015922453735369438\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0044\tGen: 0.1619\tRec: 0.1623\tE: 0.0031\tR: 0.0038\tP: 0.3225\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9415\n",
      "precision: 0.8715\n",
      "recall: 0.8783\n",
      "f1_score: 0.8727\n",
      "\n",
      "[0/100][5000/6516][Time 18.24]\n",
      "Unified LR across all optimizers: 0.00015885833107989733\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0051\tGen: 0.1603\tRec: 0.1608\tE: 0.0036\tR: 0.0044\tP: 0.3186\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9660\n",
      "precision: 0.8306\n",
      "recall: 0.8268\n",
      "f1_score: 0.8285\n",
      "\n",
      "[0/100][5050/6516][Time 18.36]\n",
      "Unified LR across all optimizers: 0.00015849296705715778\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0051\tGen: 0.1595\tRec: 0.1601\tE: 0.0036\tR: 0.0045\tP: 0.3172\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9705\n",
      "precision: 0.8813\n",
      "recall: 0.8937\n",
      "f1_score: 0.8840\n",
      "\n",
      "[0/100][5100/6516][Time 18.19]\n",
      "Unified LR across all optimizers: 0.0001581284433483521\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0046\tGen: 0.1592\tRec: 0.1597\tE: 0.0031\tR: 0.0039\tP: 0.3171\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9658\n",
      "precision: 0.8879\n",
      "recall: 0.9014\n",
      "f1_score: 0.8933\n",
      "\n",
      "[0/100][5150/6516][Time 18.37]\n",
      "Unified LR across all optimizers: 0.00015776475802081183\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0049\tGen: 0.1589\tRec: 0.1594\tE: 0.0034\tR: 0.0042\tP: 0.3160\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9704\n",
      "precision: 0.8998\n",
      "recall: 0.9018\n",
      "f1_score: 0.9001\n",
      "\n",
      "[0/100][5200/6516][Time 18.09]\n",
      "Unified LR across all optimizers: 0.00015740190914631356\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0045\tGen: 0.1568\tRec: 0.1573\tE: 0.0031\tR: 0.0040\tP: 0.3127\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9700\n",
      "precision: 0.8968\n",
      "recall: 0.9058\n",
      "f1_score: 0.9008\n",
      "\n",
      "[0/100][5250/6516][Time 18.22]\n",
      "Unified LR across all optimizers: 0.0001570398948010687\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0046\tGen: 0.1560\tRec: 0.1565\tE: 0.0032\tR: 0.0040\tP: 0.3102\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9682\n",
      "precision: 0.9010\n",
      "recall: 0.8974\n",
      "f1_score: 0.8986\n",
      "\n",
      "[0/100][5300/6516][Time 18.09]\n",
      "Unified LR across all optimizers: 0.00015667871306571324\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0049\tGen: 0.1563\tRec: 0.1569\tE: 0.0034\tR: 0.0043\tP: 0.3109\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9808\n",
      "precision: 0.8407\n",
      "recall: 0.8379\n",
      "f1_score: 0.8392\n",
      "\n",
      "[0/100][5350/6516][Time 17.79]\n",
      "Unified LR across all optimizers: 0.00015631836202529756\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0047\tGen: 0.1554\tRec: 0.1559\tE: 0.0033\tR: 0.0041\tP: 0.3090\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9626\n",
      "precision: 0.7588\n",
      "recall: 0.7590\n",
      "f1_score: 0.7587\n",
      "\n",
      "[0/100][5400/6516][Time 17.73]\n",
      "Unified LR across all optimizers: 0.00015595883976927632\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0051\tGen: 0.1542\tRec: 0.1548\tE: 0.0036\tR: 0.0044\tP: 0.3069\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9839\n",
      "precision: 0.9143\n",
      "recall: 0.9157\n",
      "f1_score: 0.9149\n",
      "\n",
      "[0/100][5450/6516][Time 17.75]\n",
      "Unified LR across all optimizers: 0.0001556001443914984\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0046\tGen: 0.1531\tRec: 0.1537\tE: 0.0032\tR: 0.0040\tP: 0.3053\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9656\n",
      "precision: 0.8181\n",
      "recall: 0.8288\n",
      "f1_score: 0.8224\n",
      "\n",
      "[0/100][5500/6516][Time 17.76]\n",
      "Unified LR across all optimizers: 0.0001552422739901963\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0042\tGen: 0.1525\tRec: 0.1530\tE: 0.0029\tR: 0.0037\tP: 0.3035\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9724\n",
      "precision: 0.9009\n",
      "recall: 0.8933\n",
      "f1_score: 0.8965\n",
      "\n",
      "[0/100][5550/6516][Time 17.74]\n",
      "Unified LR across all optimizers: 0.00015488522666797712\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0043\tGen: 0.1517\tRec: 0.1522\tE: 0.0029\tR: 0.0037\tP: 0.3015\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9417\n",
      "precision: 0.7979\n",
      "recall: 0.8249\n",
      "f1_score: 0.8098\n",
      "\n",
      "[0/100][5600/6516][Time 17.74]\n",
      "Unified LR across all optimizers: 0.00015452900053181137\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0044\tGen: 0.1512\tRec: 0.1518\tE: 0.0030\tR: 0.0038\tP: 0.3018\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9436\n",
      "precision: 0.8738\n",
      "recall: 0.8827\n",
      "f1_score: 0.8768\n",
      "\n",
      "[0/100][5650/6516][Time 17.74]\n",
      "Unified LR across all optimizers: 0.00015417359369302347\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0042\tGen: 0.1509\tRec: 0.1514\tE: 0.0029\tR: 0.0037\tP: 0.2999\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9570\n",
      "precision: 0.8678\n",
      "recall: 0.8732\n",
      "f1_score: 0.8684\n",
      "\n",
      "[0/100][5700/6516][Time 17.76]\n",
      "Unified LR across all optimizers: 0.00015381900426728195\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0042\tGen: 0.1502\tRec: 0.1507\tE: 0.0028\tR: 0.0036\tP: 0.2988\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9543\n",
      "precision: 0.8229\n",
      "recall: 0.8117\n",
      "f1_score: 0.8157\n",
      "\n",
      "[0/100][5750/6516][Time 17.74]\n",
      "Unified LR across all optimizers: 0.00015346523037458877\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0044\tGen: 0.1494\tRec: 0.1500\tE: 0.0030\tR: 0.0038\tP: 0.2979\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9657\n",
      "precision: 0.8302\n",
      "recall: 0.8328\n",
      "f1_score: 0.8312\n",
      "\n",
      "[0/100][5800/6516][Time 17.74]\n",
      "Unified LR across all optimizers: 0.00015311227013926996\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0046\tGen: 0.1491\tRec: 0.1496\tE: 0.0032\tR: 0.0040\tP: 0.2975\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9751\n",
      "precision: 0.8911\n",
      "recall: 0.9080\n",
      "f1_score: 0.8982\n",
      "\n",
      "[0/100][5850/6516][Time 18.58]\n",
      "Unified LR across all optimizers: 0.00015276012168996563\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0039\tGen: 0.1476\tRec: 0.1481\tE: 0.0026\tR: 0.0034\tP: 0.2946\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9584\n",
      "precision: 0.8167\n",
      "recall: 0.8230\n",
      "f1_score: 0.8187\n",
      "\n",
      "[0/100][5900/6516][Time 18.44]\n",
      "Unified LR across all optimizers: 0.00015240878315961963\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0044\tGen: 0.1476\tRec: 0.1481\tE: 0.0030\tR: 0.0038\tP: 0.2938\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9702\n",
      "precision: 0.8261\n",
      "recall: 0.8246\n",
      "f1_score: 0.8250\n",
      "\n",
      "[0/100][5950/6516][Time 18.26]\n",
      "Unified LR across all optimizers: 0.00015205825268547007\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0044\tGen: 0.1471\tRec: 0.1476\tE: 0.0030\tR: 0.0038\tP: 0.2930\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9572\n",
      "precision: 0.8874\n",
      "recall: 0.8842\n",
      "f1_score: 0.8851\n",
      "\n",
      "[0/100][6000/6516][Time 18.07]\n",
      "Unified LR across all optimizers: 0.0001517085284090394\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0042\tGen: 0.1463\tRec: 0.1468\tE: 0.0028\tR: 0.0036\tP: 0.2913\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9743\n",
      "precision: 0.9008\n",
      "recall: 0.9085\n",
      "f1_score: 0.9043\n",
      "\n",
      "[0/100][6050/6516][Time 17.80]\n",
      "Unified LR across all optimizers: 0.00015135960847612417\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0041\tGen: 0.1456\tRec: 0.1461\tE: 0.0028\tR: 0.0036\tP: 0.2906\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9701\n",
      "precision: 0.8257\n",
      "recall: 0.8328\n",
      "f1_score: 0.8287\n",
      "\n",
      "[0/100][6100/6516][Time 17.85]\n",
      "Unified LR across all optimizers: 0.0001510114910367858\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0038\tGen: 0.1451\tRec: 0.1456\tE: 0.0025\tR: 0.0033\tP: 0.2892\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9792\n",
      "precision: 0.9093\n",
      "recall: 0.9091\n",
      "f1_score: 0.9089\n",
      "\n",
      "[0/100][6150/6516][Time 17.72]\n",
      "Unified LR across all optimizers: 0.00015066417424534014\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0039\tGen: 0.1443\tRec: 0.1448\tE: 0.0026\tR: 0.0034\tP: 0.2872\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9651\n",
      "precision: 0.8921\n",
      "recall: 0.8860\n",
      "f1_score: 0.8882\n",
      "\n",
      "[0/100][6200/6516][Time 17.73]\n",
      "Unified LR across all optimizers: 0.00015031765626034814\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0037\tGen: 0.1444\tRec: 0.1449\tE: 0.0025\tR: 0.0032\tP: 0.2884\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9725\n",
      "precision: 0.9121\n",
      "recall: 0.9052\n",
      "f1_score: 0.9081\n",
      "\n",
      "[0/100][6250/6516][Time 17.76]\n",
      "Unified LR across all optimizers: 0.00014997193524460595\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0038\tGen: 0.1427\tRec: 0.1432\tE: 0.0026\tR: 0.0033\tP: 0.2845\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9535\n",
      "precision: 0.8939\n",
      "recall: 0.8792\n",
      "f1_score: 0.8835\n",
      "\n",
      "[0/100][6300/6516][Time 18.32]\n",
      "Unified LR across all optimizers: 0.00014962700936513516\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0040\tGen: 0.1417\tRec: 0.1423\tE: 0.0026\tR: 0.0035\tP: 0.2828\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9689\n",
      "precision: 0.8929\n",
      "recall: 0.8916\n",
      "f1_score: 0.8901\n",
      "\n",
      "[0/100][6350/6516][Time 18.84]\n",
      "Unified LR across all optimizers: 0.00014928287679317315\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0038\tGen: 0.1416\tRec: 0.1421\tE: 0.0025\tR: 0.0032\tP: 0.2825\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9639\n",
      "precision: 0.8961\n",
      "recall: 0.8936\n",
      "f1_score: 0.8939\n",
      "\n",
      "[0/100][6400/6516][Time 18.18]\n",
      "Unified LR across all optimizers: 0.0001489395357041632\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0036\tGen: 0.1413\tRec: 0.1418\tE: 0.0023\tR: 0.0031\tP: 0.2817\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9626\n",
      "precision: 0.8260\n",
      "recall: 0.8243\n",
      "f1_score: 0.8245\n",
      "\n",
      "[0/100][6450/6516][Time 17.67]\n",
      "Unified LR across all optimizers: 0.000148596984277745\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0038\tGen: 0.1405\tRec: 0.1410\tE: 0.0025\tR: 0.0033\tP: 0.2795\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9824\n",
      "precision: 0.9115\n",
      "recall: 0.9136\n",
      "f1_score: 0.9124\n",
      "\n",
      "[0/100][6500/6516][Time 17.61]\n",
      "Unified LR across all optimizers: 0.0001482552206977451\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0038\tGen: 0.1391\tRec: 0.1396\tE: 0.0025\tR: 0.0033\tP: 0.2769\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9651\n",
      "precision: 0.8345\n",
      "recall: 0.8124\n",
      "f1_score: 0.8216\n",
      "\n",
      "[1/100][34/6516][Time 17.72]\n",
      "Unified LR across all optimizers: 0.00014791424315216693\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0041\tGen: 0.1396\tRec: 0.1402\tE: 0.0027\tR: 0.0036\tP: 0.2792\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9680\n",
      "precision: 0.8298\n",
      "recall: 0.8256\n",
      "f1_score: 0.8272\n",
      "\n",
      "[1/100][84/6516][Time 17.61]\n",
      "Unified LR across all optimizers: 0.00014757404983318153\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0036\tGen: 0.1389\tRec: 0.1394\tE: 0.0024\tR: 0.0032\tP: 0.2776\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9839\n",
      "precision: 0.8364\n",
      "recall: 0.8386\n",
      "f1_score: 0.8372\n",
      "\n",
      "[1/100][134/6516][Time 17.61]\n",
      "Unified LR across all optimizers: 0.00014723463893711783\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0040\tGen: 0.1392\tRec: 0.1398\tE: 0.0027\tR: 0.0035\tP: 0.2775\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9611\n",
      "precision: 0.8946\n",
      "recall: 0.8791\n",
      "f1_score: 0.8852\n",
      "\n",
      "[1/100][184/6516][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00014689600866445298\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0035\tGen: 0.1386\tRec: 0.1391\tE: 0.0023\tR: 0.0031\tP: 0.2770\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9661\n",
      "precision: 0.8245\n",
      "recall: 0.8242\n",
      "f1_score: 0.8238\n",
      "\n",
      "[1/100][234/6516][Time 19.05]\n",
      "Unified LR across all optimizers: 0.00014655815721980301\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0030\tGen: 0.1371\tRec: 0.1374\tE: 0.0020\tR: 0.0026\tP: 0.2736\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9758\n",
      "precision: 0.9087\n",
      "recall: 0.9037\n",
      "f1_score: 0.9060\n",
      "\n",
      "[1/100][284/6516][Time 18.42]\n",
      "Unified LR across all optimizers: 0.00014622108281191326\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0039\tGen: 0.1363\tRec: 0.1368\tE: 0.0026\tR: 0.0034\tP: 0.2717\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9735\n",
      "precision: 0.8379\n",
      "recall: 0.8279\n",
      "f1_score: 0.8323\n",
      "\n",
      "[1/100][334/6516][Time 18.05]\n",
      "Unified LR across all optimizers: 0.00014588478365364866\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0037\tGen: 0.1366\tRec: 0.1371\tE: 0.0024\tR: 0.0033\tP: 0.2723\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9762\n",
      "precision: 0.9104\n",
      "recall: 0.9072\n",
      "f1_score: 0.9085\n",
      "\n",
      "[1/100][384/6516][Time 18.33]\n",
      "Unified LR across all optimizers: 0.0001455492579619846\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0036\tGen: 0.1351\tRec: 0.1356\tE: 0.0024\tR: 0.0031\tP: 0.2698\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9695\n",
      "precision: 0.8375\n",
      "recall: 0.8347\n",
      "f1_score: 0.8359\n",
      "\n",
      "[1/100][434/6516][Time 17.88]\n",
      "Unified LR across all optimizers: 0.00014521450395799725\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0036\tGen: 0.1353\tRec: 0.1358\tE: 0.0024\tR: 0.0032\tP: 0.2702\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9770\n",
      "precision: 0.9050\n",
      "recall: 0.9057\n",
      "f1_score: 0.9051\n",
      "\n",
      "[1/100][484/6516][Time 17.50]\n",
      "Unified LR across all optimizers: 0.00014488051986685427\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0033\tGen: 0.1347\tRec: 0.1351\tE: 0.0021\tR: 0.0029\tP: 0.2693\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9694\n",
      "precision: 0.8987\n",
      "recall: 0.9038\n",
      "f1_score: 0.9006\n",
      "\n",
      "[1/100][534/6516][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00014454730391780514\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0036\tGen: 0.1349\tRec: 0.1354\tE: 0.0024\tR: 0.0031\tP: 0.2692\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9809\n",
      "precision: 0.8396\n",
      "recall: 0.8372\n",
      "f1_score: 0.8383\n",
      "\n",
      "[1/100][584/6516][Time 18.38]\n",
      "Unified LR across all optimizers: 0.0001442148543441721\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0031\tGen: 0.1348\tRec: 0.1353\tE: 0.0020\tR: 0.0027\tP: 0.2688\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9742\n",
      "precision: 0.8993\n",
      "recall: 0.9072\n",
      "f1_score: 0.9025\n",
      "\n",
      "[1/100][634/6516][Time 17.92]\n",
      "Unified LR across all optimizers: 0.00014388316938334075\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0035\tGen: 0.1338\tRec: 0.1343\tE: 0.0022\tR: 0.0031\tP: 0.2673\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9648\n",
      "precision: 0.8180\n",
      "recall: 0.8149\n",
      "f1_score: 0.8150\n",
      "\n",
      "[1/100][684/6516][Time 17.93]\n",
      "Unified LR across all optimizers: 0.0001435522472767503\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0035\tGen: 0.1323\tRec: 0.1329\tE: 0.0023\tR: 0.0031\tP: 0.2642\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9737\n",
      "precision: 0.8363\n",
      "recall: 0.8330\n",
      "f1_score: 0.8343\n",
      "\n",
      "[1/100][734/6516][Time 17.90]\n",
      "Unified LR across all optimizers: 0.00014322208626988471\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0033\tGen: 0.1321\tRec: 0.1326\tE: 0.0022\tR: 0.0029\tP: 0.2640\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9662\n",
      "precision: 0.8849\n",
      "recall: 0.8942\n",
      "f1_score: 0.8876\n",
      "\n",
      "[1/100][784/6516][Time 17.98]\n",
      "Unified LR across all optimizers: 0.00014289268461226322\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0036\tGen: 0.1324\tRec: 0.1329\tE: 0.0024\tR: 0.0032\tP: 0.2642\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9774\n",
      "precision: 0.9006\n",
      "recall: 0.9037\n",
      "f1_score: 0.9015\n",
      "\n",
      "[1/100][834/6516][Time 17.96]\n",
      "Unified LR across all optimizers: 0.00014256404055743098\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0032\tGen: 0.1326\tRec: 0.1331\tE: 0.0021\tR: 0.0028\tP: 0.2652\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9761\n",
      "precision: 0.8382\n",
      "recall: 0.8379\n",
      "f1_score: 0.8377\n",
      "\n",
      "[1/100][884/6516][Time 18.20]\n",
      "Unified LR across all optimizers: 0.00014223615236295\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0036\tGen: 0.1315\tRec: 0.1320\tE: 0.0024\tR: 0.0032\tP: 0.2616\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9747\n",
      "precision: 0.9080\n",
      "recall: 0.9012\n",
      "f1_score: 0.9040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer_hub.train(trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_hub.test(testset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
