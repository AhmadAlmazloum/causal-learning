{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "        \n",
    "        KIM, JeongYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_append = \"../\"\n",
    "sys.path.append(path_append)  # Go up one directory from where you are.\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "from trainer_hub import TrainerHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>D24</th>\n",
       "      <th>D25</th>\n",
       "      <th>D26</th>\n",
       "      <th>D27</th>\n",
       "      <th>D28</th>\n",
       "      <th>D29</th>\n",
       "      <th>D30</th>\n",
       "      <th>D31</th>\n",
       "      <th>D32</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3549.790315</td>\n",
       "      <td>4533.538497</td>\n",
       "      <td>3619.665186</td>\n",
       "      <td>3077.291188</td>\n",
       "      <td>-1380.325575</td>\n",
       "      <td>6120.066816</td>\n",
       "      <td>-4072.820600</td>\n",
       "      <td>-2256.511456</td>\n",
       "      <td>1820.012261</td>\n",
       "      <td>-2815.635423</td>\n",
       "      <td>...</td>\n",
       "      <td>-7240.845997</td>\n",
       "      <td>7034.252627</td>\n",
       "      <td>8458.062496</td>\n",
       "      <td>5905.223463</td>\n",
       "      <td>6147.660515</td>\n",
       "      <td>2458.073582</td>\n",
       "      <td>-7465.876831</td>\n",
       "      <td>-3604.133966</td>\n",
       "      <td>-5445.224315</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3551.227812</td>\n",
       "      <td>4534.850995</td>\n",
       "      <td>3622.540181</td>\n",
       "      <td>3077.322438</td>\n",
       "      <td>-1377.575581</td>\n",
       "      <td>6123.066810</td>\n",
       "      <td>-4069.851856</td>\n",
       "      <td>-2252.167714</td>\n",
       "      <td>1825.168502</td>\n",
       "      <td>-2803.072947</td>\n",
       "      <td>...</td>\n",
       "      <td>-7227.283522</td>\n",
       "      <td>7039.627617</td>\n",
       "      <td>8463.874985</td>\n",
       "      <td>5911.598451</td>\n",
       "      <td>6153.504254</td>\n",
       "      <td>2463.354822</td>\n",
       "      <td>-7461.033090</td>\n",
       "      <td>-3594.258985</td>\n",
       "      <td>-5435.693082</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3556.727802</td>\n",
       "      <td>4539.850986</td>\n",
       "      <td>3629.040169</td>\n",
       "      <td>3081.978679</td>\n",
       "      <td>-1370.419344</td>\n",
       "      <td>6130.348047</td>\n",
       "      <td>-4063.508118</td>\n",
       "      <td>-2249.292720</td>\n",
       "      <td>1828.074746</td>\n",
       "      <td>-2804.041695</td>\n",
       "      <td>...</td>\n",
       "      <td>-7227.158522</td>\n",
       "      <td>7048.502600</td>\n",
       "      <td>8473.562467</td>\n",
       "      <td>5921.348433</td>\n",
       "      <td>6163.004236</td>\n",
       "      <td>2469.854810</td>\n",
       "      <td>-7460.470591</td>\n",
       "      <td>-3591.540240</td>\n",
       "      <td>-5433.568086</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3557.915300</td>\n",
       "      <td>4541.225983</td>\n",
       "      <td>3628.540169</td>\n",
       "      <td>3083.197427</td>\n",
       "      <td>-1372.263090</td>\n",
       "      <td>6130.410547</td>\n",
       "      <td>-4062.070620</td>\n",
       "      <td>-2251.667715</td>\n",
       "      <td>1825.856000</td>\n",
       "      <td>-2803.572946</td>\n",
       "      <td>...</td>\n",
       "      <td>-7224.189777</td>\n",
       "      <td>7042.346362</td>\n",
       "      <td>8464.593734</td>\n",
       "      <td>5917.660940</td>\n",
       "      <td>6160.972990</td>\n",
       "      <td>2467.011066</td>\n",
       "      <td>-7458.158095</td>\n",
       "      <td>-3597.008980</td>\n",
       "      <td>-5437.474329</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3553.352808</td>\n",
       "      <td>4535.757243</td>\n",
       "      <td>3622.477681</td>\n",
       "      <td>3079.572434</td>\n",
       "      <td>-1377.763080</td>\n",
       "      <td>6125.598056</td>\n",
       "      <td>-4066.570612</td>\n",
       "      <td>-2255.136459</td>\n",
       "      <td>1821.981008</td>\n",
       "      <td>-2808.041687</td>\n",
       "      <td>...</td>\n",
       "      <td>-7219.971035</td>\n",
       "      <td>7044.658857</td>\n",
       "      <td>8466.843729</td>\n",
       "      <td>5914.848445</td>\n",
       "      <td>6156.785498</td>\n",
       "      <td>2466.948566</td>\n",
       "      <td>-7457.501846</td>\n",
       "      <td>-3585.821500</td>\n",
       "      <td>-5428.630595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588018</th>\n",
       "      <td>-623.326974</td>\n",
       "      <td>2269.261431</td>\n",
       "      <td>2575.479615</td>\n",
       "      <td>285.733846</td>\n",
       "      <td>907.388947</td>\n",
       "      <td>-491.014719</td>\n",
       "      <td>-2998.447586</td>\n",
       "      <td>1886.043389</td>\n",
       "      <td>1659.637557</td>\n",
       "      <td>416.296105</td>\n",
       "      <td>...</td>\n",
       "      <td>-7176.689865</td>\n",
       "      <td>2116.667963</td>\n",
       "      <td>-901.138961</td>\n",
       "      <td>-227.327706</td>\n",
       "      <td>-657.170662</td>\n",
       "      <td>3025.322534</td>\n",
       "      <td>-12313.149124</td>\n",
       "      <td>-3810.071086</td>\n",
       "      <td>-5620.505241</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588019</th>\n",
       "      <td>-627.420717</td>\n",
       "      <td>2264.448940</td>\n",
       "      <td>2570.323375</td>\n",
       "      <td>281.077605</td>\n",
       "      <td>903.482705</td>\n",
       "      <td>-490.702219</td>\n",
       "      <td>-3001.260080</td>\n",
       "      <td>1884.387142</td>\n",
       "      <td>1657.012562</td>\n",
       "      <td>414.702358</td>\n",
       "      <td>...</td>\n",
       "      <td>-7179.502360</td>\n",
       "      <td>2118.074210</td>\n",
       "      <td>-900.607712</td>\n",
       "      <td>-227.046456</td>\n",
       "      <td>-659.389408</td>\n",
       "      <td>3027.760030</td>\n",
       "      <td>-12307.211635</td>\n",
       "      <td>-3809.946086</td>\n",
       "      <td>-5621.098990</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588020</th>\n",
       "      <td>-631.764459</td>\n",
       "      <td>2260.730197</td>\n",
       "      <td>2566.917131</td>\n",
       "      <td>275.546365</td>\n",
       "      <td>902.045207</td>\n",
       "      <td>-493.545964</td>\n",
       "      <td>-3006.103821</td>\n",
       "      <td>1886.199639</td>\n",
       "      <td>1658.512560</td>\n",
       "      <td>424.202340</td>\n",
       "      <td>...</td>\n",
       "      <td>-7177.439864</td>\n",
       "      <td>2118.199210</td>\n",
       "      <td>-900.920211</td>\n",
       "      <td>-226.140208</td>\n",
       "      <td>-659.764407</td>\n",
       "      <td>3027.103781</td>\n",
       "      <td>-12305.774138</td>\n",
       "      <td>-3805.633594</td>\n",
       "      <td>-5614.880251</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588021</th>\n",
       "      <td>-625.076971</td>\n",
       "      <td>2265.605188</td>\n",
       "      <td>2573.354619</td>\n",
       "      <td>281.702604</td>\n",
       "      <td>904.982702</td>\n",
       "      <td>-490.795969</td>\n",
       "      <td>-3001.416330</td>\n",
       "      <td>1888.387135</td>\n",
       "      <td>1659.418808</td>\n",
       "      <td>420.077348</td>\n",
       "      <td>...</td>\n",
       "      <td>-7172.002374</td>\n",
       "      <td>2119.730457</td>\n",
       "      <td>-898.170216</td>\n",
       "      <td>-224.515211</td>\n",
       "      <td>-656.576913</td>\n",
       "      <td>3032.822520</td>\n",
       "      <td>-12303.742892</td>\n",
       "      <td>-3804.133597</td>\n",
       "      <td>-5614.192752</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588022</th>\n",
       "      <td>-623.639474</td>\n",
       "      <td>2268.636432</td>\n",
       "      <td>2576.229614</td>\n",
       "      <td>286.515095</td>\n",
       "      <td>909.795193</td>\n",
       "      <td>-484.358481</td>\n",
       "      <td>-2996.353839</td>\n",
       "      <td>1895.730871</td>\n",
       "      <td>1668.950040</td>\n",
       "      <td>431.983576</td>\n",
       "      <td>...</td>\n",
       "      <td>-7171.908624</td>\n",
       "      <td>2129.230440</td>\n",
       "      <td>-889.357733</td>\n",
       "      <td>-216.577726</td>\n",
       "      <td>-649.358176</td>\n",
       "      <td>3039.572508</td>\n",
       "      <td>-12297.899153</td>\n",
       "      <td>-3793.383617</td>\n",
       "      <td>-5603.130273</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588023 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A1           A2           A3           A4           A5  \\\n",
       "0       3549.790315  4533.538497  3619.665186  3077.291188 -1380.325575   \n",
       "1       3551.227812  4534.850995  3622.540181  3077.322438 -1377.575581   \n",
       "2       3556.727802  4539.850986  3629.040169  3081.978679 -1370.419344   \n",
       "3       3557.915300  4541.225983  3628.540169  3083.197427 -1372.263090   \n",
       "4       3553.352808  4535.757243  3622.477681  3079.572434 -1377.763080   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "588018  -623.326974  2269.261431  2575.479615   285.733846   907.388947   \n",
       "588019  -627.420717  2264.448940  2570.323375   281.077605   903.482705   \n",
       "588020  -631.764459  2260.730197  2566.917131   275.546365   902.045207   \n",
       "588021  -625.076971  2265.605188  2573.354619   281.702604   904.982702   \n",
       "588022  -623.639474  2268.636432  2576.229614   286.515095   909.795193   \n",
       "\n",
       "                 A6           A7           A8           A9          A10  ...  \\\n",
       "0       6120.066816 -4072.820600 -2256.511456  1820.012261 -2815.635423  ...   \n",
       "1       6123.066810 -4069.851856 -2252.167714  1825.168502 -2803.072947  ...   \n",
       "2       6130.348047 -4063.508118 -2249.292720  1828.074746 -2804.041695  ...   \n",
       "3       6130.410547 -4062.070620 -2251.667715  1825.856000 -2803.572946  ...   \n",
       "4       6125.598056 -4066.570612 -2255.136459  1821.981008 -2808.041687  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "588018  -491.014719 -2998.447586  1886.043389  1659.637557   416.296105  ...   \n",
       "588019  -490.702219 -3001.260080  1884.387142  1657.012562   414.702358  ...   \n",
       "588020  -493.545964 -3006.103821  1886.199639  1658.512560   424.202340  ...   \n",
       "588021  -490.795969 -3001.416330  1888.387135  1659.418808   420.077348  ...   \n",
       "588022  -484.358481 -2996.353839  1895.730871  1668.950040   431.983576  ...   \n",
       "\n",
       "                D24          D25          D26          D27          D28  \\\n",
       "0      -7240.845997  7034.252627  8458.062496  5905.223463  6147.660515   \n",
       "1      -7227.283522  7039.627617  8463.874985  5911.598451  6153.504254   \n",
       "2      -7227.158522  7048.502600  8473.562467  5921.348433  6163.004236   \n",
       "3      -7224.189777  7042.346362  8464.593734  5917.660940  6160.972990   \n",
       "4      -7219.971035  7044.658857  8466.843729  5914.848445  6156.785498   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "588018 -7176.689865  2116.667963  -901.138961  -227.327706  -657.170662   \n",
       "588019 -7179.502360  2118.074210  -900.607712  -227.046456  -659.389408   \n",
       "588020 -7177.439864  2118.199210  -900.920211  -226.140208  -659.764407   \n",
       "588021 -7172.002374  2119.730457  -898.170216  -224.515211  -656.576913   \n",
       "588022 -7171.908624  2129.230440  -889.357733  -216.577726  -649.358176   \n",
       "\n",
       "                D29           D30          D31          D32  event  \n",
       "0       2458.073582  -7465.876831 -3604.133966 -5445.224315      5  \n",
       "1       2463.354822  -7461.033090 -3594.258985 -5435.693082      5  \n",
       "2       2469.854810  -7460.470591 -3591.540240 -5433.568086      5  \n",
       "3       2467.011066  -7458.158095 -3597.008980 -5437.474329      5  \n",
       "4       2466.948566  -7457.501846 -3585.821500 -5428.630595      5  \n",
       "...             ...           ...          ...          ...    ...  \n",
       "588018  3025.322534 -12313.149124 -3810.071086 -5620.505241     10  \n",
       "588019  3027.760030 -12307.211635 -3809.946086 -5621.098990     10  \n",
       "588020  3027.103781 -12305.774138 -3805.633594 -5614.880251     10  \n",
       "588021  3032.822520 -12303.742892 -3804.133597 -5614.192752     10  \n",
       "588022  3039.572508 -12297.899153 -3793.383617 -5603.130273     10  \n",
       "\n",
       "[588023 rows x 129 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/N-Nieto/Inner_Speech_Dataset\n",
    "\n",
    "# Load the Inner Speech Dataset\n",
    "# =============================\n",
    "# This dataset comprises raw EEG data collected from subject 'sub-01' during session 'ses-01'.\n",
    "# Source: https://github.com/N-Nieto/Inner_Speech_Dataset\n",
    "#\n",
    "# Overview:\n",
    "# - The dataset is part of a study on inner speech, capturing brain activity via EEG.\n",
    "# - Each row in the dataset corresponds to a timestamp of EEG readings.\n",
    "# - Columns represent various EEG channels (electrodes placed on the scalp).\n",
    "#\n",
    "# Usage:\n",
    "# - The data is primarily used for cognitive neuroscience research, focusing on the neural correlates of inner speech.\n",
    "# - Users can analyze EEG signals to investigate brain activity patterns associated with the cognitive processes of inner speech.\n",
    "#\n",
    "# File Structure:\n",
    "# - Located at '../data/RAW_EEG/sub-01/sub-01_ses-01.csv' relative to this script.\n",
    "# - It is advisable to preprocess the data (filtering, normalization) before detailed analysis.\n",
    "#\n",
    "# Example:\n",
    "# - To load this data into a DataFrame for analysis and processing, use the following code snippet.\n",
    "\n",
    "\n",
    "df = None\n",
    "for csv in [\"../data/RAW_EEG/sub-01/sub-01_ses-01.csv\", \"../data/RAW_EEG/sub-01/sub-01_ses-02.csv\", \"../data/RAW_EEG/sub-01/sub-01_ses-03.csv\"]:\n",
    "    tmp_df = pd.read_csv(path_append + csv)\n",
    "    if df is None:\n",
    "        df = tmp_df\n",
    "    else:\n",
    "        df = pd.concat([df, tmp_df])\n",
    "df = df.reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of each class in the 'event' column:\n",
      "event\n",
      "1     57650\n",
      "0     57650\n",
      "3     57650\n",
      "2     57650\n",
      "13    57650\n",
      "12    57650\n",
      "11    57650\n",
      "10    57650\n",
      "6     28825\n",
      "9     28825\n",
      "8     28825\n",
      "7     28825\n",
      "5     11523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Maximum class number:\n",
      "13\n",
      "\n",
      "Expected number of classes (from num_classes variable): 14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Example setup, assuming df and mm are defined as DataFrame and RobustScaler respectively\n",
    "\n",
    "# Assuming df['event'] contains the class labels\n",
    "event_counts = df['event'].value_counts()\n",
    "max_class_number = df['event'].max()\n",
    "\n",
    "# Print each number of classes\n",
    "print(\"Counts of each class in the 'event' column:\")\n",
    "print(event_counts)\n",
    "\n",
    "# Print the maximum class number\n",
    "print(\"\\nMaximum class number:\")\n",
    "print(max_class_number)\n",
    "\n",
    "num_classes = max_class_number + 1\n",
    "# Additionally, verify against the num_classes variable\n",
    "print(\"\\nExpected number of classes (from num_classes variable):\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices where the 'event' label changes: [0, 3841, 4994, 6147, 8453, 9606, 10759, 11912, 13065, 14218, 15371, 17677, 18830, 19983, 21136, 23442, 24595, 25748, 26901, 28054, 29207, 30360, 31513, 33819, 34972, 36125, 38431, 39584, 40737, 41890, 45349, 46502, 48808, 49961, 52267, 55726, 56879, 58032, 60338, 61491, 62644, 63797, 66103, 67256, 68409, 69562, 70715, 71868, 73021, 74174, 75327, 77633, 78786, 81092, 82245, 83398, 85704, 86857, 88010, 89163, 90316, 91469, 92622, 94928, 96081, 98387, 101846, 102999, 104152, 106458, 107611, 108764, 109917, 112223, 113376, 114529, 115682, 116835, 117988, 119141, 120294, 121447, 123753, 124906, 127212, 128365, 129518, 131824, 132977, 134130, 135283, 136436, 137589, 138742, 141048, 142201, 143354, 144507, 146813, 149119, 150272, 151425, 152578, 153731, 157190, 158343, 160649, 161802, 162955, 164108, 165261, 166414, 168720, 169873, 172179, 173332, 175638, 176791, 179097, 180250, 181403, 182556, 183709, 184862, 186015, 187168, 188321, 190627, 192933, 194086, 195239, 196392, 197545, 198698, 199851, 202157, 203310, 204463, 205616, 207922, 209075, 210228, 211381, 214840, 215993, 217146, 218299, 219452, 220605, 221758, 222911, 224064, 225217, 226370, 228676, 229829, 230982, 232135, 233288, 234441, 238282, 239435, 240588, 241741, 245200, 246353, 248659, 250965, 252118, 253271, 254424, 255577, 256730, 257883, 259036, 260189, 261342, 264801, 265954, 268260, 269413, 270566, 271719, 274025, 275178, 276331, 277484, 278637, 279790, 280943, 282096, 284402, 286708, 289014, 290167, 292473, 293626, 295932, 297085, 298238, 299391, 300544, 301697, 305156, 306309, 309768, 310921, 312074, 313227, 314380, 315533, 316686, 317839, 318992, 320145, 322451, 323604, 325910, 327063, 328216, 330522, 332828, 335134, 336287, 338593, 339746, 342052, 343205, 344358, 345511, 346664, 347817, 351276, 352429, 355888, 357041, 358194, 359347, 360500, 361653, 362806, 363959, 365112, 366265, 368571, 369724, 372030, 373183, 374336, 376642, 377795, 378948, 380101, 381254, 382407, 383560, 384713, 385866, 387019, 388172, 389325, 390478, 391631, 392784, 393937, 395090, 396243, 398549, 399702, 402008, 403161, 404314, 405467, 406620, 407773, 408926, 411232, 412385, 414691, 415844, 416997, 418150, 419303, 420456, 421609, 422762, 423915, 425068, 426221, 427374, 428527, 429680, 430833, 433139, 434292, 435445, 436598, 437751, 438904, 441210, 442363, 443516, 444669, 445822, 446975, 448128, 449281, 450434, 452740, 453893, 455046, 456199, 457352, 458505, 459658, 460811, 461964, 464270, 466576, 467729, 468882, 472723, 473876, 475029, 476182, 479641, 480794, 481947, 484253, 485406, 486559, 487712, 488865, 491171, 492324, 493477, 494630, 495783, 498089, 499242, 500395, 502701, 505007, 506160, 507313, 508466, 509619, 510772, 511925, 516537, 518843, 521149, 522302, 523455, 525761, 528067, 529220, 530373, 531526, 532679, 533832, 534985, 539597, 541903, 543056, 544209, 545362, 546515, 549974, 551127, 552280, 553433, 554586, 555739, 556892, 558045, 559198, 560351, 561504, 562657, 563810, 564963, 568422, 569575, 570728, 571881, 574187, 575340, 576493, 577646, 578799, 579952, 581105, 582258, 583411, 584564, 585717]\n",
      "Lengths between changes: [3841, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 2306, 1153, 1153, 1153, 3459, 1153, 2306, 1153, 2306, 3459, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 3459, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 3459, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 3459, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 3841, 1153, 1153, 1153, 3459, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 3459, 1153, 2306, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 2306, 2306, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 3459, 1153, 3459, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 2306, 2306, 2306, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 3459, 1153, 3459, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 2306, 2306, 1153, 1153, 3841, 1153, 1153, 1153, 3459, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 2306, 1153, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 4612, 2306, 2306, 1153, 1153, 2306, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 4612, 2306, 1153, 1153, 1153, 1153, 3459, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 3459, 1153, 1153, 1153, 2306, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153, 1153]\n",
      "Minimum cycle length: 1153\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is defined and already includes an 'event' column\n",
    "# Assuming 'event' column contains class labels\n",
    "event_changes = df['event'].diff().ne(0)\n",
    "change_indices = event_changes[event_changes].index.tolist()\n",
    "\n",
    "\n",
    "# Calculate and print lengths between changes\n",
    "lengths_between_changes = [change_indices[i] - change_indices[i-1] for i in range(1, len(change_indices))]\n",
    "\n",
    "# Find the minimum cycle length where the label changes\n",
    "min_cycle_length = min(lengths_between_changes)\n",
    "\n",
    "print(\"Indices where the 'event' label changes:\", change_indices)\n",
    "print(\"Lengths between changes:\", lengths_between_changes)\n",
    "print(f\"Minimum cycle length: {min_cycle_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A1        A2        A3        A4        A5        A6        A7  \\\n",
      "0 -1.356589 -1.636816 -1.800462 -1.225722 -0.127036 -0.977273  0.047727   \n",
      "1 -1.237726 -1.532338 -1.579308 -1.223097 -0.031488 -0.734848  0.263636   \n",
      "2 -0.782946 -1.134328 -1.079308 -0.832021  0.217155 -0.146465  0.725000   \n",
      "3 -0.684755 -1.024876 -1.117770 -0.729659  0.153094 -0.141414  0.829545   \n",
      "4 -1.062016 -1.460199 -1.584116 -1.034121 -0.038002 -0.530303  0.502273   \n",
      "\n",
      "         A8        A9       A10  ...       D24       D25       D26       D27  \\\n",
      "0  0.111492  0.194699  0.168491  ... -1.133240 -0.666262  0.070549 -0.252492   \n",
      "1  0.349914  0.451710  0.461709  ... -0.828892 -0.457524  0.278835  0.086379   \n",
      "2  0.507719  0.596571  0.439098  ... -0.826087 -0.112864  0.625980  0.604651   \n",
      "3  0.377358  0.485978  0.450039  ... -0.759467 -0.351942  0.304591  0.408638   \n",
      "4  0.186964  0.292831  0.345735  ... -0.664797 -0.262136  0.385218  0.259136   \n",
      "\n",
      "        D28       D29       D30       D31       D32  event  \n",
      "0 -0.272425 -0.156808 -0.475237 -2.300321 -2.263724      5  \n",
      "1  0.038206  0.001878 -0.311907 -2.057616 -2.024321      5  \n",
      "2  0.543189  0.197183 -0.292940 -1.990795 -1.970945      5  \n",
      "3  0.435216  0.111737 -0.214963 -2.125205 -2.069062      5  \n",
      "4  0.212625  0.109859 -0.192835 -1.850242 -1.846927      5  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Correctly select only the numerical columns (exclude the 'event' column) and convert to a PyTorch tensor\n",
    "df_tensor = torch.tensor(df.iloc[:, :-1].values).float().cuda()  # Using .iloc and .values to correctly handle DataFrame slicing\n",
    "\n",
    "# Define a function to perform robust scaling using PyTorch\n",
    "def robust_scale_gpu(data):\n",
    "    median = torch.median(data, dim=0).values\n",
    "    q75, q25 = torch.quantile(data, torch.tensor([0.75, 0.25], device=data.device), dim=0)\n",
    "    iqr = q75 - q25\n",
    "\n",
    "    return (data - median) / iqr\n",
    "\n",
    "for start, end in zip(change_indices[:-1], change_indices[1:]):\n",
    "    segment_length = end - start\n",
    "    if segment_length >= min_cycle_length:\n",
    "        segment = df_tensor[start:end, :]\n",
    "        scaled_segment = robust_scale_gpu(segment)\n",
    "        df_tensor[start:end, :] = scaled_segment  # Replace the original segment with the scaled data\n",
    "\n",
    "# Optionally, convert back to DataFrame if needed for further processing\n",
    "scaled_df = pd.DataFrame(df_tensor.cpu().numpy(), columns=df.columns[:-1])\n",
    "scaled_df['event'] = df['event']\n",
    "\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class EEG_Dataset(Dataset):\n",
    "    def __init__(self, df, indices, max_window_size):\n",
    "        self.df = df\n",
    "        self.indices = indices  # List of start indices\n",
    "        self.max_window_size = max_window_size\n",
    "        self.min_window_size = max_window_size // 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = self.indices[idx]\n",
    "        # Randomly choose a window size between min_window_size and max_window_size\n",
    "        window_size = random.randint(self.min_window_size, self.max_window_size)\n",
    "        \n",
    "        end_idx = start_idx + window_size\n",
    "        # Make sure the end index does not go out of the bounds of the DataFrame\n",
    "        end_idx = min(end_idx, len(self.df))\n",
    "\n",
    "        # Retrieve the sequence using the calculated indices\n",
    "        seq = self.df.iloc[start_idx:end_idx]\n",
    "        X, y = seq.values[:, :-1], seq.values[:, -1]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        # Assuming `num_classes` is defined elsewhere or passed as a parameter to __init__\n",
    "        y = torch.nn.functional.one_hot(y, num_classes=num_classes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "# Assuming 'df' is your DataFrame, 'indices' are the start indices, and 'max_window_size' is defined\n",
    "# trainset = EEG_Dataset(df, indices, max_window_size)\n",
    "# DataLoader code would follow initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "\n",
    "# Assume 'df' is your DataFrame and 'event' is the column containing labels\n",
    "\n",
    "def generate_indices(df, window_size):\n",
    "    indices = []\n",
    "    max_index = len(df) - window_size + 1  # Calculate the maximum starting index\n",
    "    \n",
    "    for i in range(max_index):\n",
    "        # Check if all labels in the window are the same\n",
    "        if len(df['event'][i:i + window_size].unique()) == 1:\n",
    "            indices.append(i)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "# Example usage\n",
    "window_size = 128\n",
    "indices = generate_indices(df, window_size)\n",
    "shuffle(indices)  # Shuffle the indices to randomize the data order\n",
    "\n",
    "# Split the indices into training and testing sets\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Assuming you have an EEG_Dataset class defined as before\n",
    "trainset = EEG_Dataset(df=scaled_df, indices=train_indices, max_window_size=128)\n",
    "testset = EEG_Dataset(df=scaled_df, indices=test_indices, max_window_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(dataset_name = 'eeg-sub-01', task_type='multi_class_classification', obs_shape=[128], label_size=num_classes)\n",
    "\n",
    "#  Set training configuration from the AlgorithmConfig class, returning them as a Namespace object.\n",
    "ml_params = MLParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_params.core_model_name = 'gpt' \n",
    "ml_params.encoder_model_name = 'none'\n",
    "ml_params.training.max_epoch = 200\n",
    "ml_params.seq_len = window_size\n",
    "\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Initialize the TrainerHub class with the training configuration, data configuration, device, and use_print and use_wandb flags\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device, use_print=True, use_wandb=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c81a23f9cbe499b92a5d892826e42c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66d8a299bfd4ae5ba465134fab4ced9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/6720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/200][50/6720][Time 18.98]\n",
      "Unified LR across all optimizers: 0.00019969466861371834\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.2927\tGen: 7.6221\tRec: 7.5979\tE: 20.2851\tR: 17.1836\tP: 955.3489\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.1726\n",
      "precision: 0.1853\n",
      "recall: 0.1410\n",
      "f1_score: 0.1038\n",
      "\n",
      "[0/200][100/6720][Time 18.12]\n",
      "Unified LR across all optimizers: 0.0001993957766378747\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.1154\tGen: 9.3493\tRec: 9.3343\tE: 8.3466\tR: 6.4254\tP: 1188.3674\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.1523\n",
      "precision: 0.1813\n",
      "recall: 0.1351\n",
      "f1_score: 0.0893\n",
      "\n",
      "[0/200][150/6720][Time 18.20]\n",
      "Unified LR across all optimizers: 0.00019909733202706992\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.1006\tGen: 7.4792\tRec: 7.4697\tE: 7.0451\tR: 5.8292\tP: 950.2886\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.2555\n",
      "precision: 0.3450\n",
      "recall: 0.2790\n",
      "f1_score: 0.2455\n",
      "\n",
      "[0/200][200/6720][Time 18.21]\n",
      "Unified LR across all optimizers: 0.00019879933411171295\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0849\tGen: 11.1792\tRec: 11.1734\tE: 5.8080\tR: 5.0571\tP: 1425.1350\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.2762\n",
      "precision: 0.3169\n",
      "recall: 0.2349\n",
      "f1_score: 0.2179\n",
      "\n",
      "[0/200][250/6720][Time 18.23]\n",
      "Unified LR across all optimizers: 0.00019850178222321458\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0789\tGen: 5.8066\tRec: 5.8012\tE: 5.3939\tR: 4.6990\tP: 737.8549\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.3601\n",
      "precision: 0.4358\n",
      "recall: 0.3802\n",
      "f1_score: 0.3295\n",
      "\n",
      "[0/200][300/6720][Time 18.20]\n",
      "Unified LR across all optimizers: 0.00019820467569398644\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0744\tGen: 11.2701\tRec: 11.2653\tE: 5.0716\tR: 4.4505\tP: 1437.5027\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.3695\n",
      "precision: 0.4005\n",
      "recall: 0.3433\n",
      "f1_score: 0.3139\n",
      "\n",
      "[0/200][350/6720][Time 18.23]\n",
      "Unified LR across all optimizers: 0.00019790801385743923\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0678\tGen: 14.2416\tRec: 14.2377\tE: 4.5836\tR: 4.0907\tP: 1818.3369\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.3646\n",
      "precision: 0.3697\n",
      "recall: 0.3905\n",
      "f1_score: 0.3385\n",
      "\n",
      "[0/200][400/6720][Time 18.24]\n",
      "Unified LR across all optimizers: 0.00019761179604798148\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0611\tGen: 6.1802\tRec: 6.1775\tE: 4.0822\tR: 3.7379\tP: 786.9855\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.4729\n",
      "precision: 0.4916\n",
      "recall: 0.4471\n",
      "f1_score: 0.3989\n",
      "\n",
      "[0/200][450/6720][Time 18.20]\n",
      "Unified LR across all optimizers: 0.00019731602160101788\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0558\tGen: 13.6114\tRec: 13.6087\tE: 3.7456\tR: 3.4022\tP: 1738.5162\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5417\n",
      "precision: 0.5383\n",
      "recall: 0.5312\n",
      "f1_score: 0.4962\n",
      "\n",
      "[0/200][500/6720][Time 18.19]\n",
      "Unified LR across all optimizers: 0.0001970206898529479\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0518\tGen: 10.2793\tRec: 10.2769\tE: 3.4670\tR: 3.1624\tP: 1312.2868\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5203\n",
      "precision: 0.4919\n",
      "recall: 0.5210\n",
      "f1_score: 0.4625\n",
      "\n",
      "[0/200][550/6720][Time 18.23]\n",
      "Unified LR across all optimizers: 0.00019672580014116413\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0484\tGen: 14.2449\tRec: 14.2434\tE: 3.1954\tR: 2.9987\tP: 1820.1534\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5459\n",
      "precision: 0.4425\n",
      "recall: 0.4905\n",
      "f1_score: 0.4305\n",
      "\n",
      "[0/200][600/6720][Time 18.23]\n",
      "Unified LR across all optimizers: 0.00019643135180405117\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0455\tGen: 9.1903\tRec: 9.1888\tE: 3.0029\tR: 2.8183\tP: 1173.3537\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5117\n",
      "precision: 0.5098\n",
      "recall: 0.5089\n",
      "f1_score: 0.4615\n",
      "\n",
      "[0/200][650/6720][Time 18.28]\n",
      "Unified LR across all optimizers: 0.00019613734418098366\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0415\tGen: 6.9736\tRec: 6.9725\tE: 2.7239\tR: 2.5872\tP: 889.8916\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5330\n",
      "precision: 0.5809\n",
      "recall: 0.5094\n",
      "f1_score: 0.4843\n",
      "\n",
      "[0/200][700/6720][Time 18.12]\n",
      "Unified LR across all optimizers: 0.00019584377661232514\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0399\tGen: 13.7273\tRec: 13.7270\tE: 2.5741\tR: 2.5370\tP: 1754.5207\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.4747\n",
      "precision: 0.5862\n",
      "recall: 0.5872\n",
      "f1_score: 0.5000\n",
      "\n",
      "[0/200][750/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.0001955506484394265\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0365\tGen: 7.2409\tRec: 7.2403\tE: 2.3773\tR: 2.2911\tP: 924.4613\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5530\n",
      "precision: 0.6407\n",
      "recall: 0.6389\n",
      "f1_score: 0.5656\n",
      "\n",
      "[0/200][800/6720][Time 17.90]\n",
      "Unified LR across all optimizers: 0.00019525795900462422\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0350\tGen: 8.8168\tRec: 8.8163\tE: 2.2670\tR: 2.2083\tP: 1126.2815\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5864\n",
      "precision: 0.6605\n",
      "recall: 0.6325\n",
      "f1_score: 0.5978\n",
      "\n",
      "[0/200][850/6720][Time 17.76]\n",
      "Unified LR across all optimizers: 0.0001949657076512394\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0344\tGen: 13.4122\tRec: 13.4123\tE: 2.1977\tR: 2.2043\tP: 1714.5642\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5776\n",
      "precision: 0.6616\n",
      "recall: 0.6442\n",
      "f1_score: 0.6047\n",
      "\n",
      "[0/200][900/6720][Time 18.35]\n",
      "Unified LR across all optimizers: 0.00019467389372357586\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0310\tGen: 13.2221\tRec: 13.2222\tE: 1.9750\tR: 1.9873\tP: 1690.4520\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6255\n",
      "precision: 0.6722\n",
      "recall: 0.6284\n",
      "f1_score: 0.5764\n",
      "\n",
      "[0/200][950/6720][Time 18.34]\n",
      "Unified LR across all optimizers: 0.00019438251656691888\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0298\tGen: 13.4664\tRec: 13.4667\tE: 1.8875\tR: 1.9307\tP: 1721.8057\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5945\n",
      "precision: 0.7308\n",
      "recall: 0.6959\n",
      "f1_score: 0.6649\n",
      "\n",
      "[0/200][1000/6720][Time 18.21]\n",
      "Unified LR across all optimizers: 0.00019409157552753375\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0278\tGen: 12.0609\tRec: 12.0616\tE: 1.7313\tR: 1.8213\tP: 1542.0680\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.5532\n",
      "precision: 0.6177\n",
      "recall: 0.6350\n",
      "f1_score: 0.5666\n",
      "\n",
      "[0/200][1050/6720][Time 17.61]\n",
      "Unified LR across all optimizers: 0.00019380106995266398\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0260\tGen: 12.6222\tRec: 12.6225\tE: 1.6449\tR: 1.6791\tP: 1614.0026\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6603\n",
      "precision: 0.6951\n",
      "recall: 0.6589\n",
      "f1_score: 0.6163\n",
      "\n",
      "[0/200][1100/6720][Time 18.08]\n",
      "Unified LR across all optimizers: 0.00019351099919053054\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0250\tGen: 8.2371\tRec: 8.2378\tE: 1.5541\tR: 1.6475\tP: 1052.7926\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6475\n",
      "precision: 0.6813\n",
      "recall: 0.6791\n",
      "f1_score: 0.6218\n",
      "\n",
      "[0/200][1150/6720][Time 17.78]\n",
      "Unified LR across all optimizers: 0.00019322136259032944\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0234\tGen: 8.2900\tRec: 8.2908\tE: 1.4444\tR: 1.5494\tP: 1059.6714\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7178\n",
      "precision: 0.7270\n",
      "recall: 0.7412\n",
      "f1_score: 0.6959\n",
      "\n",
      "[0/200][1200/6720][Time 17.71]\n",
      "Unified LR across all optimizers: 0.00019293215950223126\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0217\tGen: 4.5589\tRec: 4.5599\tE: 1.3248\tR: 1.4526\tP: 582.2168\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6792\n",
      "precision: 0.7112\n",
      "recall: 0.6771\n",
      "f1_score: 0.6351\n",
      "\n",
      "[0/200][1250/6720][Time 18.27]\n",
      "Unified LR across all optimizers: 0.00019264338927737882\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0212\tGen: 9.9101\tRec: 9.9109\tE: 1.3054\tR: 1.4030\tP: 1267.1887\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7132\n",
      "precision: 0.7895\n",
      "recall: 0.8144\n",
      "f1_score: 0.7555\n",
      "\n",
      "[0/200][1300/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00019235505126788632\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0193\tGen: 9.7599\tRec: 9.7610\tE: 1.1690\tR: 1.3012\tP: 1248.1023\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6951\n",
      "precision: 0.7729\n",
      "recall: 0.7929\n",
      "f1_score: 0.7260\n",
      "\n",
      "[0/200][1350/6720][Time 17.60]\n",
      "Unified LR across all optimizers: 0.0001920671448268376\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0186\tGen: 9.7298\tRec: 9.7308\tE: 1.1249\tR: 1.2577\tP: 1244.2848\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6444\n",
      "precision: 0.7573\n",
      "recall: 0.7391\n",
      "f1_score: 0.7091\n",
      "\n",
      "[0/200][1400/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.0001917796693082847\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0180\tGen: 8.9206\tRec: 8.9217\tE: 1.0824\tR: 1.2183\tP: 1140.7603\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7233\n",
      "precision: 0.8045\n",
      "recall: 0.8104\n",
      "f1_score: 0.7556\n",
      "\n",
      "[0/200][1450/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00019149262406724683\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0163\tGen: 9.5333\tRec: 9.5344\tE: 0.9687\tR: 1.1158\tP: 1219.2879\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7362\n",
      "precision: 0.7994\n",
      "recall: 0.7712\n",
      "f1_score: 0.7375\n",
      "\n",
      "[0/200][1500/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00019120600845970806\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0167\tGen: 17.7815\tRec: 17.7829\tE: 0.9815\tR: 1.1533\tP: 2275.0524\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7046\n",
      "precision: 0.6582\n",
      "recall: 0.6472\n",
      "f1_score: 0.6122\n",
      "\n",
      "[0/200][1550/6720][Time 18.28]\n",
      "Unified LR across all optimizers: 0.00019091982184261694\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0157\tGen: 12.2068\tRec: 12.2080\tE: 0.9313\tR: 1.0832\tP: 1561.5438\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7109\n",
      "precision: 0.7328\n",
      "recall: 0.7603\n",
      "f1_score: 0.7007\n",
      "\n",
      "[0/200][1600/6720][Time 17.77]\n",
      "Unified LR across all optimizers: 0.0001906340635738838\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0153\tGen: 9.3955\tRec: 9.3967\tE: 0.9053\tR: 1.0586\tP: 1201.7249\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7021\n",
      "precision: 0.7992\n",
      "recall: 0.8049\n",
      "f1_score: 0.7559\n",
      "\n",
      "[0/200][1650/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.0001903487330123808\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0142\tGen: 13.6853\tRec: 13.6867\tE: 0.8237\tR: 0.9927\tP: 1750.9010\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7104\n",
      "precision: 0.7769\n",
      "recall: 0.7884\n",
      "f1_score: 0.7369\n",
      "\n",
      "[0/200][1700/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.000190063829517939\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0134\tGen: 9.9932\tRec: 9.9945\tE: 0.7777\tR: 0.9389\tP: 1278.3568\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7267\n",
      "precision: 0.7594\n",
      "recall: 0.7483\n",
      "f1_score: 0.7128\n",
      "\n",
      "[0/200][1750/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.00018977935245134824\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0132\tGen: 6.1445\tRec: 6.1456\tE: 0.7727\tR: 0.9213\tP: 785.7212\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7424\n",
      "precision: 0.8001\n",
      "recall: 0.8253\n",
      "f1_score: 0.7715\n",
      "\n",
      "[0/200][1800/6720][Time 17.61]\n",
      "Unified LR across all optimizers: 0.00018949530117435472\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0128\tGen: 8.5341\tRec: 8.5354\tE: 0.7351\tR: 0.9007\tP: 1091.6241\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6985\n",
      "precision: 0.7702\n",
      "recall: 0.7792\n",
      "f1_score: 0.7332\n",
      "\n",
      "[0/200][1850/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.00018921167504965984\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0131\tGen: 18.0333\tRec: 18.0343\tE: 0.7668\tR: 0.9043\tP: 2307.4897\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6523\n",
      "precision: 0.7874\n",
      "recall: 0.8040\n",
      "f1_score: 0.7603\n",
      "\n",
      "[0/200][1900/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00018892847344091938\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0121\tGen: 12.6759\tRec: 12.6772\tE: 0.6929\tR: 0.8514\tP: 1621.8245\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7535\n",
      "precision: 0.8455\n",
      "recall: 0.8566\n",
      "f1_score: 0.7980\n",
      "\n",
      "[0/200][1950/6720][Time 17.67]\n",
      "Unified LR across all optimizers: 0.0001886456957127411\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0119\tGen: 8.9640\tRec: 8.9652\tE: 0.6906\tR: 0.8389\tP: 1146.7025\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7156\n",
      "precision: 0.7569\n",
      "recall: 0.7669\n",
      "f1_score: 0.7203\n",
      "\n",
      "[0/200][2000/6720][Time 17.62]\n",
      "Unified LR across all optimizers: 0.00018836334123068405\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0115\tGen: 11.3344\tRec: 11.3355\tE: 0.6625\tR: 0.8139\tP: 1450.1346\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7354\n",
      "precision: 0.8241\n",
      "recall: 0.8565\n",
      "f1_score: 0.7955\n",
      "\n",
      "[0/200][2050/6720][Time 17.68]\n",
      "Unified LR across all optimizers: 0.0001880814093612565\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0118\tGen: 13.2409\tRec: 13.2419\tE: 0.6891\tR: 0.8194\tP: 1694.1444\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7747\n",
      "precision: 0.7581\n",
      "recall: 0.7701\n",
      "f1_score: 0.7414\n",
      "\n",
      "[0/200][2100/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.0001877998994719154\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0110\tGen: 9.6120\tRec: 9.6130\tE: 0.6432\tR: 0.7708\tP: 1229.6988\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7385\n",
      "precision: 0.7716\n",
      "recall: 0.7839\n",
      "f1_score: 0.7386\n",
      "\n",
      "[0/200][2150/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.00018751881093106415\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0114\tGen: 13.7848\tRec: 13.7852\tE: 0.7007\tR: 0.7576\tP: 1763.7513\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6965\n",
      "precision: 0.7451\n",
      "recall: 0.7431\n",
      "f1_score: 0.6963\n",
      "\n",
      "[0/200][2200/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00018723814310805145\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0103\tGen: 8.1693\tRec: 8.1699\tE: 0.6190\tR: 0.7017\tP: 1045.0499\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7877\n",
      "precision: 0.8384\n",
      "recall: 0.8452\n",
      "f1_score: 0.7963\n",
      "\n",
      "[0/200][2250/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00018695789537317\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0100\tGen: 9.5083\tRec: 9.5094\tE: 0.5740\tR: 0.7085\tP: 1216.4925\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7184\n",
      "precision: 0.8171\n",
      "recall: 0.8417\n",
      "f1_score: 0.7801\n",
      "\n",
      "[0/200][2300/6720][Time 18.04]\n",
      "Unified LR across all optimizers: 0.00018667806709765522\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0103\tGen: 11.3730\tRec: 11.3742\tE: 0.5847\tR: 0.7356\tP: 1455.1625\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7308\n",
      "precision: 0.8352\n",
      "recall: 0.7755\n",
      "f1_score: 0.7881\n",
      "\n",
      "[0/200][2350/6720][Time 18.29]\n",
      "Unified LR across all optimizers: 0.00018639865765368338\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0101\tGen: 13.1343\tRec: 13.1353\tE: 0.5814\tR: 0.7071\tP: 1680.6084\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6699\n",
      "precision: 0.7573\n",
      "recall: 0.7445\n",
      "f1_score: 0.7088\n",
      "\n",
      "[0/200][2400/6720][Time 18.25]\n",
      "Unified LR across all optimizers: 0.00018611966641437044\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0201\tGen: 9.9168\tRec: 9.9273\tE: 0.6145\tR: 1.9602\tP: 1268.7320\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7773\n",
      "precision: 0.7777\n",
      "recall: 0.7899\n",
      "f1_score: 0.7474\n",
      "\n",
      "[0/200][2450/6720][Time 18.30]\n",
      "Unified LR across all optimizers: 0.00018584109275377077\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0103\tGen: 9.0316\tRec: 9.0328\tE: 0.5830\tR: 0.7334\tP: 1155.4666\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7047\n",
      "precision: 0.8431\n",
      "recall: 0.8576\n",
      "f1_score: 0.8133\n",
      "\n",
      "[0/200][2500/6720][Time 18.28]\n",
      "Unified LR across all optimizers: 0.00018556293604687557\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0100\tGen: 11.8041\tRec: 11.8052\tE: 0.5769\tR: 0.7086\tP: 1510.3535\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7341\n",
      "precision: 0.8329\n",
      "recall: 0.8292\n",
      "f1_score: 0.7893\n",
      "\n",
      "[0/200][2550/6720][Time 18.23]\n",
      "Unified LR across all optimizers: 0.00018528519566961144\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0094\tGen: 7.6090\tRec: 7.6099\tE: 0.5455\tR: 0.6612\tP: 973.4113\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7369\n",
      "precision: 0.8459\n",
      "recall: 0.8575\n",
      "f1_score: 0.8135\n",
      "\n",
      "[0/200][2600/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00018500787099883916\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0095\tGen: 5.9050\tRec: 5.9060\tE: 0.5426\tR: 0.6740\tP: 755.2942\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7238\n",
      "precision: 0.8438\n",
      "recall: 0.8393\n",
      "f1_score: 0.7959\n",
      "\n",
      "[0/200][2650/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00018473096141235213\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0091\tGen: 9.6824\tRec: 9.6834\tE: 0.5175\tR: 0.6460\tP: 1238.8316\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7522\n",
      "precision: 0.8433\n",
      "recall: 0.8433\n",
      "f1_score: 0.7892\n",
      "\n",
      "[0/200][2700/6720][Time 17.68]\n",
      "Unified LR across all optimizers: 0.00018445446628887513\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0092\tGen: 7.8491\tRec: 7.8502\tE: 0.5176\tR: 0.6540\tP: 1004.1663\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7426\n",
      "precision: 0.8292\n",
      "recall: 0.8425\n",
      "f1_score: 0.7868\n",
      "\n",
      "[0/200][2750/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00018417838500806271\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0098\tGen: 8.7670\tRec: 8.7678\tE: 0.5811\tR: 0.6736\tP: 1121.6001\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7041\n",
      "precision: 0.7580\n",
      "recall: 0.7626\n",
      "f1_score: 0.7138\n",
      "\n",
      "[0/200][2800/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00018390271695049802\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0089\tGen: 15.6049\tRec: 15.6053\tE: 0.5452\tR: 0.5925\tP: 1996.8849\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7050\n",
      "precision: 0.7664\n",
      "recall: 0.7679\n",
      "f1_score: 0.7234\n",
      "\n",
      "[0/200][2850/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.00018362746149769128\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0087\tGen: 6.0958\tRec: 6.0961\tE: 0.5345\tR: 0.5764\tP: 779.7289\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7175\n",
      "precision: 0.8440\n",
      "recall: 0.8566\n",
      "f1_score: 0.8052\n",
      "\n",
      "[0/200][2900/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00018335261803207844\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0088\tGen: 10.5186\tRec: 10.5192\tE: 0.5247\tR: 0.6014\tP: 1345.8532\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7325\n",
      "precision: 0.7785\n",
      "recall: 0.7827\n",
      "f1_score: 0.7485\n",
      "\n",
      "[0/200][2950/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00018307818593701973\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0086\tGen: 8.1134\tRec: 8.1140\tE: 0.5120\tR: 0.5839\tP: 1038.0039\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7395\n",
      "precision: 0.8416\n",
      "recall: 0.8442\n",
      "f1_score: 0.8084\n",
      "\n",
      "[0/200][3000/6720][Time 17.68]\n",
      "Unified LR across all optimizers: 0.00018280416459679836\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0085\tGen: 9.7500\tRec: 9.7508\tE: 0.4946\tR: 0.5976\tP: 1247.5076\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7696\n",
      "precision: 0.8489\n",
      "recall: 0.8578\n",
      "f1_score: 0.8155\n",
      "\n",
      "[0/200][3050/6720][Time 17.75]\n",
      "Unified LR across all optimizers: 0.00018253055339661917\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0081\tGen: 9.2481\tRec: 9.2489\tE: 0.4660\tR: 0.5730\tP: 1183.2850\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7239\n",
      "precision: 0.8327\n",
      "recall: 0.8502\n",
      "f1_score: 0.7969\n",
      "\n",
      "[0/200][3100/6720][Time 18.26]\n",
      "Unified LR across all optimizers: 0.000182257351722607\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0084\tGen: 7.3459\tRec: 7.3467\tE: 0.4852\tR: 0.5848\tP: 939.7894\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7469\n",
      "precision: 0.7714\n",
      "recall: 0.7859\n",
      "f1_score: 0.7449\n",
      "\n",
      "[0/200][3150/6720][Time 18.11]\n",
      "Unified LR across all optimizers: 0.00018198455896180582\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0082\tGen: 8.5985\tRec: 8.5993\tE: 0.4746\tR: 0.5731\tP: 1100.1359\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7194\n",
      "precision: 0.6910\n",
      "recall: 0.6868\n",
      "f1_score: 0.6489\n",
      "\n",
      "[0/200][3200/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00018171217450217676\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0079\tGen: 9.6418\tRec: 9.6426\tE: 0.4579\tR: 0.5553\tP: 1233.6975\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7292\n",
      "precision: 0.7798\n",
      "recall: 0.7970\n",
      "f1_score: 0.7400\n",
      "\n",
      "[0/200][3250/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00018144019773259714\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0081\tGen: 8.1845\tRec: 8.1850\tE: 0.4851\tR: 0.5541\tP: 1047.1291\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7358\n",
      "precision: 0.8376\n",
      "recall: 0.7824\n",
      "f1_score: 0.7931\n",
      "\n",
      "[0/200][3300/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.00018116862804285912\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0077\tGen: 10.7541\tRec: 10.7546\tE: 0.4620\tR: 0.5241\tP: 1376.0648\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7474\n",
      "precision: 0.8472\n",
      "recall: 0.8634\n",
      "f1_score: 0.8111\n",
      "\n",
      "[0/200][3350/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00018089746482366777\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0077\tGen: 2.2579\tRec: 2.2586\tE: 0.4461\tR: 0.5381\tP: 288.5644\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7660\n",
      "precision: 0.8358\n",
      "recall: 0.8513\n",
      "f1_score: 0.8053\n",
      "\n",
      "[0/200][3400/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.0001806267074666406\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0080\tGen: 10.6126\tRec: 10.6128\tE: 0.5006\tR: 0.5290\tP: 1357.9094\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7510\n",
      "precision: 0.8427\n",
      "recall: 0.8433\n",
      "f1_score: 0.8054\n",
      "\n",
      "[0/200][3450/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00018035635536430543\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0077\tGen: 5.1404\tRec: 5.1406\tE: 0.4828\tR: 0.5003\tP: 657.4923\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7084\n",
      "precision: 0.8292\n",
      "recall: 0.8506\n",
      "f1_score: 0.8032\n",
      "\n",
      "[0/200][3500/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.00018008640791009926\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0072\tGen: 9.3153\tRec: 9.3155\tE: 0.4480\tR: 0.4776\tP: 1191.9081\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7028\n",
      "precision: 0.6952\n",
      "recall: 0.7095\n",
      "f1_score: 0.6616\n",
      "\n",
      "[0/200][3550/6720][Time 18.13]\n",
      "Unified LR across all optimizers: 0.00017981686449836722\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0074\tGen: 9.7443\tRec: 9.7450\tE: 0.4305\tR: 0.5110\tP: 1246.8458\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7438\n",
      "precision: 0.7758\n",
      "recall: 0.7891\n",
      "f1_score: 0.7433\n",
      "\n",
      "[0/200][3600/6720][Time 17.81]\n",
      "Unified LR across all optimizers: 0.0001795477245243606\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0073\tGen: 9.9232\tRec: 9.9236\tE: 0.4371\tR: 0.4963\tP: 1269.7285\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7131\n",
      "precision: 0.8437\n",
      "recall: 0.8615\n",
      "f1_score: 0.8111\n",
      "\n",
      "[0/200][3650/6720][Time 17.59]\n",
      "Unified LR across all optimizers: 0.00017927898738423638\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0073\tGen: 8.2943\tRec: 8.2949\tE: 0.4290\tR: 0.5041\tP: 1061.2376\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7473\n",
      "precision: 0.8493\n",
      "recall: 0.8663\n",
      "f1_score: 0.8221\n",
      "\n",
      "[0/200][3700/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00017901065247505463\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0070\tGen: 7.1364\tRec: 7.1370\tE: 0.4117\tR: 0.4847\tP: 913.0497\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7252\n",
      "precision: 0.8471\n",
      "recall: 0.8474\n",
      "f1_score: 0.7959\n",
      "\n",
      "[0/200][3750/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00017874271919477843\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0070\tGen: 8.6883\tRec: 8.6889\tE: 0.4123\tR: 0.4880\tP: 1111.6892\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7183\n",
      "precision: 0.8356\n",
      "recall: 0.8506\n",
      "f1_score: 0.8010\n",
      "\n",
      "[0/200][3800/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.0001784751869422717\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0071\tGen: 8.0826\tRec: 8.0832\tE: 0.4180\tR: 0.4878\tP: 1034.1564\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7446\n",
      "precision: 0.8459\n",
      "recall: 0.8397\n",
      "f1_score: 0.7985\n",
      "\n",
      "[0/200][3850/6720][Time 17.67]\n",
      "Unified LR across all optimizers: 0.0001782080551172982\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0068\tGen: 10.0497\tRec: 10.0502\tE: 0.4068\tR: 0.4657\tP: 1285.9565\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7509\n",
      "precision: 0.7135\n",
      "recall: 0.7104\n",
      "f1_score: 0.6705\n",
      "\n",
      "[0/200][3900/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.0001779413231205201\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0068\tGen: 11.7405\tRec: 11.7410\tE: 0.4074\tR: 0.4691\tP: 1502.3790\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7371\n",
      "precision: 0.8535\n",
      "recall: 0.8629\n",
      "f1_score: 0.8156\n",
      "\n",
      "[0/200][3950/6720][Time 17.67]\n",
      "Unified LR across all optimizers: 0.00017767499035349662\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0070\tGen: 12.9817\tRec: 12.9820\tE: 0.4253\tR: 0.4677\tP: 1661.2337\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7227\n",
      "precision: 0.8390\n",
      "recall: 0.8493\n",
      "f1_score: 0.7935\n",
      "\n",
      "[0/200][4000/6720][Time 17.62]\n",
      "Unified LR across all optimizers: 0.00017740905621868258\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0068\tGen: 9.2916\tRec: 9.2920\tE: 0.4104\tR: 0.4575\tP: 1188.9160\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7117\n",
      "precision: 0.7739\n",
      "recall: 0.7833\n",
      "f1_score: 0.7400\n",
      "\n",
      "[0/200][4050/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00017714352011942726\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0069\tGen: 9.6660\tRec: 9.6665\tE: 0.4034\tR: 0.4739\tP: 1236.8438\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7522\n",
      "precision: 0.7600\n",
      "recall: 0.7700\n",
      "f1_score: 0.7133\n",
      "\n",
      "[0/200][4100/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00017687838145997293\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0065\tGen: 12.0839\tRec: 12.0843\tE: 0.3931\tR: 0.4450\tP: 1546.3454\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7140\n",
      "precision: 0.7799\n",
      "recall: 0.7851\n",
      "f1_score: 0.7446\n",
      "\n",
      "[0/200][4150/6720][Time 17.61]\n",
      "Unified LR across all optimizers: 0.00017661363964545368\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0064\tGen: 12.8734\tRec: 12.8737\tE: 0.3885\tR: 0.4290\tP: 1647.4080\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7242\n",
      "precision: 0.7051\n",
      "recall: 0.7038\n",
      "f1_score: 0.6569\n",
      "\n",
      "[0/200][4200/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00017634929408189386\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0066\tGen: 5.1023\tRec: 5.1026\tE: 0.4024\tR: 0.4423\tP: 652.6966\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7240\n",
      "precision: 0.8497\n",
      "recall: 0.8683\n",
      "f1_score: 0.8133\n",
      "\n",
      "[0/200][4250/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.00017608534417620688\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0065\tGen: 3.2269\tRec: 3.2273\tE: 0.3926\tR: 0.4353\tP: 412.6543\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7163\n",
      "precision: 0.8280\n",
      "recall: 0.8341\n",
      "f1_score: 0.7890\n",
      "\n",
      "[0/200][4300/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.0001758217893361938\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0064\tGen: 9.0200\tRec: 9.0199\tE: 0.4166\tR: 0.4073\tP: 1154.1380\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7347\n",
      "precision: 0.7798\n",
      "recall: 0.7885\n",
      "f1_score: 0.7332\n",
      "\n",
      "[0/200][4350/6720][Time 18.02]\n",
      "Unified LR across all optimizers: 0.00017555862897054202\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0064\tGen: 9.9526\tRec: 9.9527\tE: 0.4024\tR: 0.4138\tP: 1273.5275\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7216\n",
      "precision: 0.7801\n",
      "recall: 0.7775\n",
      "f1_score: 0.7372\n",
      "\n",
      "[0/200][4400/6720][Time 18.06]\n",
      "Unified LR across all optimizers: 0.0001752958624888243\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0062\tGen: 14.9375\tRec: 14.9378\tE: 0.3797\tR: 0.4180\tP: 1911.6203\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7392\n",
      "precision: 0.8450\n",
      "recall: 0.8517\n",
      "f1_score: 0.8140\n",
      "\n",
      "[0/200][4450/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00017503348930149678\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0063\tGen: 9.5757\tRec: 9.5756\tE: 0.4078\tR: 0.3956\tP: 1225.2768\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.6993\n",
      "precision: 0.8483\n",
      "recall: 0.8542\n",
      "f1_score: 0.8063\n",
      "\n",
      "[0/200][4500/6720][Time 17.67]\n",
      "Unified LR across all optimizers: 0.000174771508819898\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0061\tGen: 6.2343\tRec: 6.2342\tE: 0.3950\tR: 0.3846\tP: 797.5972\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7354\n",
      "precision: 0.8583\n",
      "recall: 0.8622\n",
      "f1_score: 0.8280\n",
      "\n",
      "[0/200][4550/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.00017450992045624762\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0058\tGen: 11.4489\tRec: 11.4491\tE: 0.3578\tR: 0.3891\tP: 1465.1015\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7411\n",
      "precision: 0.8470\n",
      "recall: 0.8591\n",
      "f1_score: 0.8067\n",
      "\n",
      "[0/200][4600/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00017424872362364514\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0060\tGen: 12.2681\tRec: 12.2683\tE: 0.3726\tR: 0.3893\tP: 1569.9474\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7422\n",
      "precision: 0.8446\n",
      "recall: 0.8620\n",
      "f1_score: 0.8219\n",
      "\n",
      "[0/200][4650/6720][Time 17.70]\n",
      "Unified LR across all optimizers: 0.0001739879177360685\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0058\tGen: 12.1579\tRec: 12.1581\tE: 0.3583\tR: 0.3813\tP: 1555.8510\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7372\n",
      "precision: 0.8583\n",
      "recall: 0.8546\n",
      "f1_score: 0.8150\n",
      "\n",
      "[0/200][4700/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.0001737275022083727\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0061\tGen: 6.2719\tRec: 6.2715\tE: 0.4173\tR: 0.3663\tP: 802.3853\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7524\n",
      "precision: 0.8574\n",
      "recall: 0.8495\n",
      "f1_score: 0.8171\n",
      "\n",
      "[0/200][4750/6720][Time 17.70]\n",
      "Unified LR across all optimizers: 0.00017346747645628874\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0059\tGen: 11.3156\tRec: 11.3155\tE: 0.3837\tR: 0.3683\tP: 1448.0173\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7098\n",
      "precision: 0.7107\n",
      "recall: 0.7144\n",
      "f1_score: 0.6679\n",
      "\n",
      "[0/200][4800/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.0001732078398964217\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0058\tGen: 12.6267\tRec: 12.6265\tE: 0.3855\tR: 0.3585\tP: 1615.8353\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7529\n",
      "precision: 0.7847\n",
      "recall: 0.7880\n",
      "f1_score: 0.7385\n",
      "\n",
      "[0/200][4850/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.0001729485919462503\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0058\tGen: 8.6354\tRec: 8.6352\tE: 0.3874\tR: 0.3532\tP: 1104.9500\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7273\n",
      "precision: 0.8393\n",
      "recall: 0.8483\n",
      "f1_score: 0.7944\n",
      "\n",
      "[0/200][4900/6720][Time 18.20]\n",
      "Unified LR across all optimizers: 0.00017268973202412484\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0058\tGen: 7.5841\tRec: 7.5840\tE: 0.3813\tR: 0.3603\tP: 970.3885\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7501\n",
      "precision: 0.7822\n",
      "recall: 0.7917\n",
      "f1_score: 0.7445\n",
      "\n",
      "[0/200][4950/6720][Time 17.79]\n",
      "Unified LR across all optimizers: 0.00017243125954926648\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0058\tGen: 7.0701\tRec: 7.0698\tE: 0.3871\tR: 0.3514\tP: 904.5870\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7729\n",
      "precision: 0.8535\n",
      "recall: 0.8656\n",
      "f1_score: 0.8132\n",
      "\n",
      "[0/200][5000/6720][Time 17.61]\n",
      "Unified LR across all optimizers: 0.00017217317394176534\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0057\tGen: 5.8237\tRec: 5.8236\tE: 0.3685\tR: 0.3567\tP: 745.0694\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7781\n",
      "precision: 0.8449\n",
      "recall: 0.8595\n",
      "f1_score: 0.8026\n",
      "\n",
      "[0/200][5050/6720][Time 17.60]\n",
      "Unified LR across all optimizers: 0.00017191547462257976\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0056\tGen: 9.5792\tRec: 9.5792\tE: 0.3554\tR: 0.3605\tP: 1225.7765\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7223\n",
      "precision: 0.8531\n",
      "recall: 0.8593\n",
      "f1_score: 0.8145\n",
      "\n",
      "[0/200][5100/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00017165816101353477\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0056\tGen: 8.4873\tRec: 8.4876\tE: 0.3414\tR: 0.3774\tP: 1086.0369\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7764\n",
      "precision: 0.8568\n",
      "recall: 0.8613\n",
      "f1_score: 0.8132\n",
      "\n",
      "[0/200][5150/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00017140123253732057\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0056\tGen: 9.6648\tRec: 9.6651\tE: 0.3471\tR: 0.3750\tP: 1236.7535\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7502\n",
      "precision: 0.8475\n",
      "recall: 0.8680\n",
      "f1_score: 0.8133\n",
      "\n",
      "[0/200][5200/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00017114468861749145\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0055\tGen: 8.0895\tRec: 8.0897\tE: 0.3375\tR: 0.3615\tP: 1035.1156\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7345\n",
      "precision: 0.8553\n",
      "recall: 0.8558\n",
      "f1_score: 0.8051\n",
      "\n",
      "[0/200][5250/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.0001708885286784647\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0055\tGen: 9.3297\tRec: 9.3299\tE: 0.3402\tR: 0.3583\tP: 1193.8642\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7246\n",
      "precision: 0.8629\n",
      "recall: 0.8675\n",
      "f1_score: 0.8247\n",
      "\n",
      "[0/200][5300/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00017063275214551914\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0055\tGen: 9.8700\tRec: 9.8699\tE: 0.3613\tR: 0.3411\tP: 1263.0039\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7427\n",
      "precision: 0.8542\n",
      "recall: 0.8565\n",
      "f1_score: 0.8148\n",
      "\n",
      "[0/200][5350/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00017037735844479363\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0054\tGen: 7.4741\tRec: 7.4742\tE: 0.3364\tR: 0.3532\tP: 956.3433\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7271\n",
      "precision: 0.7804\n",
      "recall: 0.7918\n",
      "f1_score: 0.7474\n",
      "\n",
      "[0/200][5400/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.0001701223470032859\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0053\tGen: 11.4437\tRec: 11.4438\tE: 0.3336\tR: 0.3457\tP: 1464.4615\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7722\n",
      "precision: 0.7827\n",
      "recall: 0.7932\n",
      "f1_score: 0.7455\n",
      "\n",
      "[0/200][5450/6720][Time 17.62]\n",
      "Unified LR across all optimizers: 0.00016986771724885146\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0054\tGen: 8.1393\tRec: 8.1391\tE: 0.3559\tR: 0.3361\tP: 1041.4749\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7622\n",
      "precision: 0.7838\n",
      "recall: 0.7977\n",
      "f1_score: 0.7510\n",
      "\n",
      "[0/200][5500/6720][Time 17.68]\n",
      "Unified LR across all optimizers: 0.00016961346861020217\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0054\tGen: 9.2224\tRec: 9.2219\tE: 0.3726\tR: 0.3184\tP: 1180.0895\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7270\n",
      "precision: 0.8410\n",
      "recall: 0.8549\n",
      "f1_score: 0.8055\n",
      "\n",
      "[0/200][5550/6720][Time 18.10]\n",
      "Unified LR across all optimizers: 0.00016935960051690484\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0053\tGen: 12.8241\tRec: 12.8241\tE: 0.3424\tR: 0.3374\tP: 1641.1433\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7771\n",
      "precision: 0.7806\n",
      "recall: 0.7980\n",
      "f1_score: 0.7480\n",
      "\n",
      "[0/200][5600/6720][Time 17.87]\n",
      "Unified LR across all optimizers: 0.0001691061123993802\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0053\tGen: 8.7804\tRec: 8.7804\tE: 0.3337\tR: 0.3396\tP: 1123.5559\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7537\n",
      "precision: 0.8530\n",
      "recall: 0.8740\n",
      "f1_score: 0.8188\n",
      "\n",
      "[0/200][5650/6720][Time 17.87]\n",
      "Unified LR across all optimizers: 0.0001688530036889014\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0052\tGen: 9.2150\tRec: 9.2149\tE: 0.3394\tR: 0.3251\tP: 1179.1816\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7784\n",
      "precision: 0.7950\n",
      "recall: 0.7949\n",
      "f1_score: 0.7610\n",
      "\n",
      "[0/200][5700/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.000168600273817593\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0053\tGen: 16.9747\tRec: 16.9742\tE: 0.3676\tR: 0.3069\tP: 2172.3913\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7384\n",
      "precision: 0.7871\n",
      "recall: 0.7931\n",
      "f1_score: 0.7543\n",
      "\n",
      "[0/200][5750/6720][Time 17.62]\n",
      "Unified LR across all optimizers: 0.00016834792221842926\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0051\tGen: 10.1292\tRec: 10.1289\tE: 0.3470\tR: 0.3074\tP: 1296.1882\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7294\n",
      "precision: 0.8504\n",
      "recall: 0.8572\n",
      "f1_score: 0.8114\n",
      "\n",
      "[0/200][5800/6720][Time 17.62]\n",
      "Unified LR across all optimizers: 0.00016809594832523344\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0051\tGen: 12.7852\tRec: 12.7849\tE: 0.3430\tR: 0.3130\tP: 1636.1597\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7485\n",
      "precision: 0.8489\n",
      "recall: 0.8675\n",
      "f1_score: 0.8168\n",
      "\n",
      "[0/200][5850/6720][Time 17.65]\n",
      "Unified LR across all optimizers: 0.00016784435157267603\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0050\tGen: 4.9033\tRec: 4.9032\tE: 0.3281\tR: 0.3114\tP: 627.2983\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7512\n",
      "precision: 0.7857\n",
      "recall: 0.7996\n",
      "f1_score: 0.7541\n",
      "\n",
      "[0/200][5900/6720][Time 17.67]\n",
      "Unified LR across all optimizers: 0.00016759313139627356\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0050\tGen: 11.3788\tRec: 11.3785\tE: 0.3378\tR: 0.3019\tP: 1456.1474\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7413\n",
      "precision: 0.8553\n",
      "recall: 0.8622\n",
      "f1_score: 0.8047\n",
      "\n",
      "[0/200][5950/6720][Time 17.63]\n",
      "Unified LR across all optimizers: 0.00016734228723238773\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0050\tGen: 14.9311\tRec: 14.9307\tE: 0.3488\tR: 0.2930\tP: 1910.8365\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7210\n",
      "precision: 0.7762\n",
      "recall: 0.7960\n",
      "f1_score: 0.7489\n",
      "\n",
      "[0/200][6000/6720][Time 17.67]\n",
      "Unified LR across all optimizers: 0.0001670918185182238\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0049\tGen: 11.4033\tRec: 11.4033\tE: 0.3174\tR: 0.3093\tP: 1459.3096\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7645\n",
      "precision: 0.7082\n",
      "recall: 0.7289\n",
      "f1_score: 0.6885\n",
      "\n",
      "[0/200][6050/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.00016684172469182913\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0048\tGen: 7.0521\tRec: 7.0522\tE: 0.2994\tR: 0.3101\tP: 902.3750\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7473\n",
      "precision: 0.8568\n",
      "recall: 0.8629\n",
      "f1_score: 0.8306\n",
      "\n",
      "[0/200][6100/6720][Time 17.60]\n",
      "Unified LR across all optimizers: 0.0001665920051920924\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0047\tGen: 8.0156\tRec: 8.0156\tE: 0.3017\tR: 0.3016\tP: 1025.6950\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7300\n",
      "precision: 0.8592\n",
      "recall: 0.8687\n",
      "f1_score: 0.8211\n",
      "\n",
      "[0/200][6150/6720][Time 17.62]\n",
      "Unified LR across all optimizers: 0.00016634265945874216\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0050\tGen: 7.2236\tRec: 7.2234\tE: 0.3366\tR: 0.3067\tP: 924.2848\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7559\n",
      "precision: 0.8514\n",
      "recall: 0.8682\n",
      "f1_score: 0.8170\n",
      "\n",
      "[0/200][6200/6720][Time 17.61]\n",
      "Unified LR across all optimizers: 0.0001660936869323454\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0055\tGen: 7.5494\tRec: 7.5484\tE: 0.4128\tR: 0.2857\tP: 965.9078\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7843\n",
      "precision: 0.8589\n",
      "recall: 0.8640\n",
      "f1_score: 0.8227\n",
      "\n",
      "[0/200][6250/6720][Time 17.62]\n",
      "Unified LR across all optimizers: 0.00016584508705430652\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0049\tGen: 12.6947\tRec: 12.6945\tE: 0.3227\tR: 0.2991\tP: 1624.5937\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7115\n",
      "precision: 0.8640\n",
      "recall: 0.8623\n",
      "f1_score: 0.8179\n",
      "\n",
      "[0/200][6300/6720][Time 17.60]\n",
      "Unified LR across all optimizers: 0.00016559685926686616\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0046\tGen: 9.5698\tRec: 9.5698\tE: 0.2933\tR: 0.2943\tP: 1224.6382\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7167\n",
      "precision: 0.7866\n",
      "recall: 0.7912\n",
      "f1_score: 0.7445\n",
      "\n",
      "[0/200][6350/6720][Time 17.64]\n",
      "Unified LR across all optimizers: 0.0001653490030130995\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0048\tGen: 5.5896\tRec: 5.5895\tE: 0.3160\tR: 0.3003\tP: 715.1505\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7693\n",
      "precision: 0.7812\n",
      "recall: 0.7259\n",
      "f1_score: 0.7370\n",
      "\n",
      "[0/200][6400/6720][Time 17.66]\n",
      "Unified LR across all optimizers: 0.00016510151773691523\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0047\tGen: 11.4043\tRec: 11.4038\tE: 0.3295\tR: 0.2748\tP: 1459.4166\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7535\n",
      "precision: 0.7771\n",
      "recall: 0.7963\n",
      "f1_score: 0.7414\n",
      "\n",
      "[0/200][6450/6720][Time 17.80]\n",
      "Unified LR across all optimizers: 0.0001648544028830548\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0047\tGen: 9.7695\tRec: 9.7693\tE: 0.3179\tR: 0.2882\tP: 1250.1835\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7454\n",
      "precision: 0.6437\n",
      "recall: 0.6430\n",
      "f1_score: 0.5945\n",
      "\n",
      "[0/200][6500/6720][Time 18.35]\n",
      "Unified LR across all optimizers: 0.0001646076578970904\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0048\tGen: 10.9934\tRec: 10.9930\tE: 0.3357\tR: 0.2801\tP: 1406.8176\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7246\n",
      "precision: 0.8583\n",
      "recall: 0.8643\n",
      "f1_score: 0.8166\n",
      "\n",
      "[0/200][6550/6720][Time 18.35]\n",
      "Unified LR across all optimizers: 0.00016436128222542429\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0047\tGen: 8.6540\tRec: 8.6535\tE: 0.3290\tR: 0.2664\tP: 1107.3874\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7317\n",
      "precision: 0.7866\n",
      "recall: 0.7940\n",
      "f1_score: 0.7492\n",
      "\n",
      "[0/200][6600/6720][Time 18.31]\n",
      "Unified LR across all optimizers: 0.00016411527531528698\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0048\tGen: 9.7044\tRec: 9.7039\tE: 0.3381\tR: 0.2700\tP: 1241.8261\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7625\n",
      "precision: 0.7985\n",
      "recall: 0.7916\n",
      "f1_score: 0.7586\n",
      "\n",
      "[0/200][6650/6720][Time 18.27]\n",
      "Unified LR across all optimizers: 0.00016386963661473657\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0046\tGen: 11.6591\tRec: 11.6590\tE: 0.2960\tR: 0.2903\tP: 1492.0676\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7712\n",
      "precision: 0.7827\n",
      "recall: 0.7994\n",
      "f1_score: 0.7574\n",
      "\n",
      "[0/200][6700/6720][Time 18.21]\n",
      "Unified LR across all optimizers: 0.00016362436557265726\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0046\tGen: 10.3521\tRec: 10.3519\tE: 0.3076\tR: 0.2771\tP: 1324.7597\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7335\n",
      "precision: 0.7877\n",
      "recall: 0.7961\n",
      "f1_score: 0.7603\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d42f1660f934eef93a8604fca6cf268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/6720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200][30/6720][Time 18.27]\n",
      "Unified LR across all optimizers: 0.00016337946163875813\n",
      "--------------------Training Metrics--------------------\n",
      "Trainer:  gpt\n",
      "Inf: 0.0046\tGen: 10.2054\tRec: 10.2050\tE: 0.3209\tR: 0.2637\tP: 1305.9715\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.7200\n",
      "precision: 0.8504\n",
      "recall: 0.8677\n",
      "f1_score: 0.8130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer_hub.train(trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_hub.test(testset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
