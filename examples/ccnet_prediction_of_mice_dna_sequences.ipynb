{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Authors : Jinsu Kim, JunHo Park\n",
        "\n",
        "â“’ 2022 CCNets, Inc. All Rights Reserved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://ccnets.org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "path_append = \"../\"\n",
        "sys.path.append(path_append)  # Go up one directory from where you are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the base directory and CSV file name\n",
        "base_dir = path_append + \"../data/\"  # Update this to the directory where your data folder is located\n",
        "csv_file = \"Data_Cortex_Nuclear.csv\"  # Update this to your CSV file name if different\n",
        "\n",
        "# Full path to the CSV file\n",
        "full_path = os.path.join(base_dir, csv_file)\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv(full_path)\n",
        "    print(\"Data loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Failed to load data. File not found at:\", full_path)\n",
        "\n",
        "# No need for image_size here unless it is used later in your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TrainLoader / DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Preprocess dataset\n",
        "df = df.drop(\"MouseID\", axis=1)\n",
        "label_cols = [\"Genotype\", \"Treatment\", \"Behavior\", \"class\"]\n",
        "for col in label_cols:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Impute missing values\n",
        "imputer = IterativeImputer(max_iter=10, random_state=0)  # max_iter was num_features; adjust as appropriate\n",
        "df[:] = imputer.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "feature_cols = df.columns[df.columns != 'class']\n",
        "df[feature_cols] = StandardScaler().fit_transform(df[feature_cols])\n",
        "\n",
        "# Determine number of features and classes\n",
        "num_features = len(feature_cols)\n",
        "num_classes = len(df['class'].unique())\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[feature_cols], df['class'], test_size=0.2, random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom dataset class\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.x = torch.tensor(features, dtype=torch.float32)\n",
        "        self.y = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Dataset instances\n",
        "train_dataset = CustomDataset(X_train.values, y_train.values)\n",
        "test_dataset = CustomDataset(X_test.values, y_test.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "for features, labels in train_dataset:\n",
        "    print(features, labels)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tools.setting.ml_params import MLParameters\n",
        "from tools.setting.data_config import DataConfig\n",
        "\n",
        "data_config = DataConfig(dataset_name = 'genetic_variant', task_type='multi_class_classification', obs_shape=[num_features], label_size=num_classes)\n",
        "#  Set training configuration from the AlgorithmConfig class, returning them as a Namespace object.\n",
        "ml_params = MLParameters(core_model = 'gpt', encoder_model = 'none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trainer_hub import TrainerHub\n",
        "\n",
        "# Set the device to GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "\n",
        "# Initialize the TrainerHub class with the training configuration, data configuration, device, and use_print and use_wandb flags\n",
        "trainer_hub = TrainerHub(ml_params, data_config, device, use_print=True, use_wandb=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "metadata": {
      "interpreter": {
        "hash": "a7e81af88087f1f4bdc1f0426df14b24fa2673362c5daa7f7f9146748f40b3b1"
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "aa62b0cd3048c1f98ba81d64726d0b99961f9a4c88743680dc76385f8ef59940"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
